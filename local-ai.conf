# Configuration file for the application

# Flags for different functionalities
# Enable F16 functionality
# F16=false
# Enable gallery autoloading
# AUTOLOAD_GALLERIES=false
# Enable debug mode
# DEBUG=false
# Allow only one backend to be running
# SINGLE_ACTIVE_BACKEND=false
# Enable CORS
# CORS=false
# Set allowed CORS origins
# CORS_ALLOW_ORIGINS=""

# Threading configuration
# Number of threads for parallel computation
# THREADS=4

# Paths for models and galleries
# Path containing models used for inference
MODELS_PATH="/var/lib/local-ai/models"
# JSON list of galleries
GALLERIES='[{"name":"model-gallery", "url":"github:go-skynet/model-gallery/index.yaml"}, {"url": "github:go-skynet/model-gallery/huggingface.yaml","name":"huggingface"}]'
# List of models to preload at startup
# PRELOAD_MODELS=""
# Path to a YAML config file for preloading models
# PRELOAD_MODELS_CONFIG=""
# Path to the config file
LOCALAI_CONFIG_DIR="/etc/local-ai"

# Server address and directories
# Bind address for the API server
# ADDRESS=":8080"
# Directory for images
IMAGE_PATH="/var/lib/local-ai/generated/images"
# Directory for audio
AUDIO_PATH="/var/lib/local-ai/generated/audio"
# Path to backend assets
BACKEND_ASSETS_PATH="/var/lib/local-ai/backend_data"

# External GRPC backends
# List of external GRPC backends
EXTERNAL_GRPC_BACKENDS="huggingface-embeddings:/build/extra/grpc/huggingface/huggingface.py,autogptq:/build/extra/grpc/autogptq/autogptq.py,bark:/build/extra/grpc/bark/ttsbark.py,diffusers:/build/extra/grpc/diffusers/backend_diffusers.py,exllama:/build/extra/grpc/exllama/exllama.py,vall-e-x:/build/extra/grpc/vall-e-x/ttsvalle.py,vllm:/build/extra/grpc/vllm/backend_vllm.py"

# Model context and upload settings
# Default context size of the model
# CONTEXT_SIZE=512
# Default upload-limit in MB
# UPLOAD_LIMIT=15
# List of API Keys for API authentication
# API_KEY=()
# If set, the API is not launched and only the preloaded models/backends are started
# PRELOAD_BACKEND_ONLY=false
