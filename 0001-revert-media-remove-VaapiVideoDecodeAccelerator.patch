
# https://github.com/chromium/chromium/commit/6fb414a7d51f46940cf9c45df04f6ee398f8da1b
media: remove VaapiVideoDecodeAccelerator

# https://github.com/chromium/chromium/commit/064f82bf9239232b1619ca68a7487425f7cc328c
# media: remove legacy VDA code from gpu_mojo_media_client_linux.cc

# https://github.com/chromium/chromium/commit/5c0666589e3a0099e1559d9f172d79e1289cca98
# add CHECK to make sure the VaapiVDA path is never taken

---
diff --git a/gpu/command_buffer/service/shared_image/gl_image_native_pixmap.h b/gpu/command_buffer/service/shared_image/gl_image_native_pixmap.h
index cb1659a..d2b80d0 100644
--- a/gpu/command_buffer/service/shared_image/gl_image_native_pixmap.h
+++ b/gpu/command_buffer/service/shared_image/gl_image_native_pixmap.h
@@ -14,6 +14,7 @@
 
 namespace media {
 class V4L2SliceVideoDecodeAccelerator;
+class VaapiPictureNativePixmapOzone;
 }  // namespace media
 
 namespace ui {
@@ -62,6 +63,7 @@ class GPU_GLES2_EXPORT GLImageNativePixmap : public gl::GLImage {
  private:
   friend class gles2::GLES2DecoderImpl;
   friend class media::V4L2SliceVideoDecodeAccelerator;
+  friend class media::VaapiPictureNativePixmapOzone;
 
   explicit GLImageNativePixmap(const gfx::Size& size);
   ~GLImageNativePixmap() override;
diff --git a/media/gpu/gpu_video_decode_accelerator_factory.cc b/media/gpu/gpu_video_decode_accelerator_factory.cc
index 8611ffa..a5feeda 100644
--- a/media/gpu/gpu_video_decode_accelerator_factory.cc
+++ b/media/gpu/gpu_video_decode_accelerator_factory.cc
@@ -19,7 +19,10 @@
 #if BUILDFLAG(IS_APPLE)
 #include "media/gpu/mac/vt_video_decode_accelerator_mac.h"
 #endif
-#if BUILDFLAG(USE_V4L2_CODEC) && \
+#if BUILDFLAG(USE_VAAPI)
+#include "media/gpu/vaapi/vaapi_video_decode_accelerator.h"
+#include "ui/gl/gl_implementation.h"
+#elif BUILDFLAG(USE_V4L2_CODEC) && \
     (BUILDFLAG(IS_LINUX) || BUILDFLAG(IS_CHROMEOS_ASH))
 #include "media/gpu/v4l2/v4l2_device.h"
 #include "media/gpu/v4l2/legacy/v4l2_slice_video_decode_accelerator.h"
@@ -46,7 +49,10 @@ gpu::VideoDecodeAcceleratorCapabilities GetDecoderCapabilitiesInternal(
   // resolutions and other supported profile parameters.
   VideoDecodeAccelerator::Capabilities capabilities;
 #if BUILDFLAG(USE_CHROMEOS_MEDIA_ACCELERATION)
-#if BUILDFLAG(USE_V4L2_CODEC) && \
+#if BUILDFLAG(USE_VAAPI)
+  capabilities.supported_profiles =
+      VaapiVideoDecodeAccelerator::GetSupportedProfiles();
+#elif BUILDFLAG(USE_V4L2_CODEC) && \
     (BUILDFLAG(IS_LINUX) || BUILDFLAG(IS_CHROMEOS_ASH))
   GpuVideoAcceleratorUtil::InsertUniqueDecodeProfiles(
       V4L2VideoDecodeAccelerator::GetSupportedProfiles(),
@@ -123,7 +129,12 @@ GpuVideoDecodeAcceleratorFactory::CreateVDA(
                                            const gpu::GpuPreferences&,
                                            MediaLog* media_log) const;
   const CreateVDAFp create_vda_fps[] = {
-#if BUILDFLAG(USE_V4L2_CODEC) && \
+  // Usually only one of USE_VAAPI or USE_V4L2_CODEC is defined on ChromeOS,
+  // except for Chromeboxes with companion video acceleration chips, which have
+  // both. In those cases prefer the VA creation function.
+#if BUILDFLAG(USE_VAAPI)
+    &GpuVideoDecodeAcceleratorFactory::CreateVaapiVDA,
+#elif BUILDFLAG(USE_V4L2_CODEC) && \
     (BUILDFLAG(IS_LINUX) || BUILDFLAG(IS_CHROMEOS_ASH))
     &GpuVideoDecodeAcceleratorFactory::CreateV4L2VDA,
     &GpuVideoDecodeAcceleratorFactory::CreateV4L2SliceVDA,
@@ -145,7 +156,18 @@ GpuVideoDecodeAcceleratorFactory::CreateVDA(
   return nullptr;
 }
 
-#if BUILDFLAG(USE_V4L2_CODEC) && \
+#if BUILDFLAG(USE_VAAPI)
+std::unique_ptr<VideoDecodeAccelerator>
+GpuVideoDecodeAcceleratorFactory::CreateVaapiVDA(
+    const gpu::GpuDriverBugWorkarounds& /*workarounds*/,
+    const gpu::GpuPreferences& /*gpu_preferences*/,
+    MediaLog* /*media_log*/) const {
+  std::unique_ptr<VideoDecodeAccelerator> decoder;
+  decoder.reset(new VaapiVideoDecodeAccelerator(gl_client_.make_context_current,
+                                                gl_client_.bind_image));
+  return decoder;
+}
+#elif BUILDFLAG(USE_V4L2_CODEC) && \
     (BUILDFLAG(IS_LINUX) || BUILDFLAG(IS_CHROMEOS_ASH))
 std::unique_ptr<VideoDecodeAccelerator>
 GpuVideoDecodeAcceleratorFactory::CreateV4L2VDA(
diff --git a/media/gpu/vaapi/BUILD.gn b/media/gpu/vaapi/BUILD.gn
index 7d54384..e65f994 100644
--- a/media/gpu/vaapi/BUILD.gn
+++ b/media/gpu/vaapi/BUILD.gn
@@ -56,6 +56,12 @@ source_set("vaapi") {
     "vaapi_jpeg_decoder.h",
     "vaapi_jpeg_encoder.cc",
     "vaapi_jpeg_encoder.h",
+    "vaapi_picture.cc",
+    "vaapi_picture.h",
+    "vaapi_picture_factory.cc",
+    "vaapi_picture_factory.h",
+    "vaapi_video_decode_accelerator.cc",
+    "vaapi_video_decode_accelerator.h",
     "vaapi_video_decoder.cc",
     "vaapi_video_decoder.h",
     "vaapi_video_decoder_delegate.cc",
@@ -128,6 +134,43 @@ source_set("vaapi") {
       "//components/chromeos_camera:mjpeg_decode_accelerator",
     ]
   }
+
+  if (use_ozone || use_egl) {
+    sources += [
+      "vaapi_picture_native_pixmap.cc",
+      "vaapi_picture_native_pixmap.h",
+    ]
+  }
+
+  if (use_vaapi_x11) {
+    deps += [ "//ui/gfx/x" ]
+    sources += [
+      "gl_image_egl_pixmap.cc",
+      "gl_image_egl_pixmap.h",
+      "vaapi_picture_native_pixmap_angle.cc",
+      "vaapi_picture_native_pixmap_angle.h",
+    ]
+  }
+
+  if (use_ozone) {
+    deps += [
+      "//media/gpu:buffer_validation",
+      "//ui/ozone",
+    ]
+    sources += [
+      "vaapi_picture_native_pixmap_ozone.cc",
+      "vaapi_picture_native_pixmap_ozone.h",
+    ]
+  }
+
+  if (use_egl) {
+    sources += [
+      "gl_image_gl_texture.cc",
+      "gl_image_gl_texture.h",
+      "vaapi_picture_native_pixmap_egl.cc",
+      "vaapi_picture_native_pixmap_egl.h",
+    ]
+  }
 }
 
 # The vaapi status functionality is in its own source set so that it can be
@@ -204,6 +247,7 @@ source_set("unit_test") {
   sources = [
     "h264_vaapi_video_encoder_delegate_unittest.cc",
     "vaapi_image_decode_accelerator_worker_unittest.cc",
+    "vaapi_video_decode_accelerator_unittest.cc",
     "vaapi_video_encode_accelerator_unittest.cc",
     "vaapi_wrapper_unittest.cc",
     "vp9_vaapi_video_encoder_delegate_unittest.cc",
diff --git a/media/gpu/vaapi/gl_image_egl_pixmap.cc b/media/gpu/vaapi/gl_image_egl_pixmap.cc
new file mode 100644
index 0000000..5d636e9
--- /dev/null
+++ b/media/gpu/vaapi/gl_image_egl_pixmap.cc
@@ -0,0 +1,26 @@
+// Copyright 2020 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "media/gpu/vaapi/gl_image_egl_pixmap.h"
+
+namespace media {
+
+GLImageEGLPixmap::GLImageEGLPixmap(const gfx::Size& size)
+    : binding_helper_(size) {}
+
+GLImageEGLPixmap::~GLImageEGLPixmap() = default;
+
+bool GLImageEGLPixmap::Initialize(x11::Pixmap pixmap) {
+  return binding_helper_.Initialize(pixmap);
+}
+
+bool GLImageEGLPixmap::BindTexImage(unsigned target) {
+  return binding_helper_.BindTexImage(target);
+}
+
+void GLImageEGLPixmap::ReleaseEGLImage() {
+  return binding_helper_.ReleaseEGLImage();
+}
+
+}  // namespace media
diff --git a/media/gpu/vaapi/gl_image_egl_pixmap.h b/media/gpu/vaapi/gl_image_egl_pixmap.h
new file mode 100644
index 0000000..66d23fe
--- /dev/null
+++ b/media/gpu/vaapi/gl_image_egl_pixmap.h
@@ -0,0 +1,44 @@
+// Copyright 2020 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef MEDIA_GPU_VAAPI_GL_IMAGE_EGL_PIXMAP_H_
+#define MEDIA_GPU_VAAPI_GL_IMAGE_EGL_PIXMAP_H_
+
+#include "ui/gfx/geometry/size.h"
+#include "ui/gfx/x/glx.h"
+#include "ui/gl/gl_image.h"
+#include "ui/gl/native_pixmap_egl_x11_binding_helper.h"
+
+namespace media {
+
+class VaapiPictureNativePixmapAngle;
+
+class GLImageEGLPixmap : public gl::GLImage {
+  // NOTE: We are in the process of eliminating this class, so no new usages
+  // of it should be introduced.
+ private:
+  friend class VaapiPictureNativePixmapAngle;
+
+  explicit GLImageEGLPixmap(const gfx::Size& size);
+
+  GLImageEGLPixmap(const GLImageEGLPixmap&) = delete;
+  GLImageEGLPixmap& operator=(const GLImageEGLPixmap&) = delete;
+
+  bool Initialize(x11::Pixmap pixmap);
+
+  // Binds image to texture currently bound to |target|. Returns true on
+  // success.
+  bool BindTexImage(unsigned target);
+
+  // Releases the image that was bound via BindTexImage().
+  void ReleaseEGLImage();
+
+  ~GLImageEGLPixmap() override;
+
+  gl::NativePixmapEGLX11BindingHelper binding_helper_;
+};
+
+}  // namespace media
+
+#endif  // MEDIA_GPU_VAAPI_GL_IMAGE_EGL_PIXMAP_H_
diff --git a/media/gpu/vaapi/gl_image_gl_texture.cc b/media/gpu/vaapi/gl_image_gl_texture.cc
new file mode 100644
index 0000000..28b8490
--- /dev/null
+++ b/media/gpu/vaapi/gl_image_gl_texture.cc
@@ -0,0 +1,230 @@
+// Copyright 2023 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "media/gpu/vaapi/gl_image_gl_texture.h"
+
+#include <vector>
+
+#include "base/files/scoped_file.h"
+#include "ui/gfx/buffer_format_util.h"
+#include "ui/gl/buffer_format_utils.h"
+#include "ui/gl/egl_util.h"
+#include "ui/gl/gl_bindings.h"
+#include "ui/gl/gl_context.h"
+#include "ui/gl/gl_surface_egl.h"
+
+#define FOURCC(a, b, c, d)                                        \
+  ((static_cast<uint32_t>(a)) | (static_cast<uint32_t>(b) << 8) | \
+   (static_cast<uint32_t>(c) << 16) | (static_cast<uint32_t>(d) << 24))
+
+#define DRM_FORMAT_R8 FOURCC('R', '8', ' ', ' ')
+#define DRM_FORMAT_R16 FOURCC('R', '1', '6', ' ')
+#define DRM_FORMAT_GR88 FOURCC('G', 'R', '8', '8')
+#define DRM_FORMAT_GR1616 FOURCC('G', 'R', '3', '2')
+#define DRM_FORMAT_RGB565 FOURCC('R', 'G', '1', '6')
+#define DRM_FORMAT_ARGB8888 FOURCC('A', 'R', '2', '4')
+#define DRM_FORMAT_ABGR8888 FOURCC('A', 'B', '2', '4')
+#define DRM_FORMAT_XRGB8888 FOURCC('X', 'R', '2', '4')
+#define DRM_FORMAT_XBGR8888 FOURCC('X', 'B', '2', '4')
+#define DRM_FORMAT_ABGR2101010 FOURCC('A', 'B', '3', '0')
+#define DRM_FORMAT_ARGB2101010 FOURCC('A', 'R', '3', '0')
+#define DRM_FORMAT_YVU420 FOURCC('Y', 'V', '1', '2')
+#define DRM_FORMAT_NV12 FOURCC('N', 'V', '1', '2')
+#define DRM_FORMAT_P010 FOURCC('P', '0', '1', '0')
+
+namespace media {
+namespace {
+
+// Returns corresponding internalformat if supported, and GL_NONE otherwise.
+unsigned GLInternalFormat(gfx::BufferFormat format) {
+  switch (format) {
+    case gfx::BufferFormat::RGBA_4444:
+    case gfx::BufferFormat::RGBA_F16:
+    case gfx::BufferFormat::P010:
+      return GL_RGB_YCBCR_P010_CHROMIUM;
+    default:
+      break;
+  }
+  return gl::BufferFormatToGLInternalFormat(format);
+}
+
+gfx::BufferFormat GetBufferFormatFromFourCCFormat(int format) {
+  switch (format) {
+    case DRM_FORMAT_R8:
+      return gfx::BufferFormat::R_8;
+    case DRM_FORMAT_GR88:
+      return gfx::BufferFormat::RG_88;
+    case DRM_FORMAT_ABGR8888:
+      return gfx::BufferFormat::RGBA_8888;
+    case DRM_FORMAT_XBGR8888:
+      return gfx::BufferFormat::RGBX_8888;
+    case DRM_FORMAT_ARGB8888:
+      return gfx::BufferFormat::BGRA_8888;
+    case DRM_FORMAT_XRGB8888:
+      return gfx::BufferFormat::BGRX_8888;
+    case DRM_FORMAT_ABGR2101010:
+      return gfx::BufferFormat::RGBA_1010102;
+    case DRM_FORMAT_ARGB2101010:
+      return gfx::BufferFormat::BGRA_1010102;
+    case DRM_FORMAT_RGB565:
+      return gfx::BufferFormat::BGR_565;
+    case DRM_FORMAT_NV12:
+      return gfx::BufferFormat::YUV_420_BIPLANAR;
+    case DRM_FORMAT_YVU420:
+      return gfx::BufferFormat::YVU_420;
+    case DRM_FORMAT_P010:
+      return gfx::BufferFormat::P010;
+    default:
+      NOTREACHED_NORETURN();
+  }
+}
+
+}  // namespace
+
+scoped_refptr<GLImageGLTexture> GLImageGLTexture::CreateFromTexture(
+    const gfx::Size& size,
+    gfx::BufferFormat format,
+    uint32_t texture_id) {
+  auto image = base::WrapRefCounted(new GLImageGLTexture(size, format));
+  if (!image->InitializeFromTexture(texture_id)) {
+    return nullptr;
+  }
+  return image;
+}
+
+GLImageGLTexture::GLImageGLTexture(const gfx::Size& size,
+                                   gfx::BufferFormat format)
+    : egl_image_(EGL_NO_IMAGE_KHR),
+      size_(size),
+      format_(format),
+      has_image_dma_buf_export_(gl::GLSurfaceEGL::GetGLDisplayEGL()
+                                    ->ext->b_EGL_MESA_image_dma_buf_export) {}
+
+GLImageGLTexture::~GLImageGLTexture() {
+  DCHECK_CALLED_ON_VALID_THREAD(thread_checker_);
+  if (egl_image_ == EGL_NO_IMAGE_KHR) {
+    return;
+  }
+
+  const EGLBoolean result = eglDestroyImageKHR(
+      gl::GLSurfaceEGL::GetGLDisplayEGL()->GetDisplay(), egl_image_);
+  if (result == EGL_FALSE) {
+    DLOG(ERROR) << "Error destroying EGLImage: " << ui::GetLastEGLErrorString();
+  }
+}
+
+bool GLImageGLTexture::InitializeFromTexture(uint32_t texture_id) {
+  if (GLInternalFormat(format_) == GL_NONE) {
+    LOG(ERROR) << "Unsupported format: " << gfx::BufferFormatToString(format_);
+    return false;
+  }
+  gl::GLContext* current_context = gl::GLContext::GetCurrent();
+  if (!current_context || !current_context->IsCurrent(nullptr)) {
+    LOG(ERROR) << "No gl context bound to the current thread";
+    return false;
+  }
+
+  EGLContext context_handle =
+      reinterpret_cast<EGLContext>(current_context->GetHandle());
+  DCHECK_NE(context_handle, EGL_NO_CONTEXT);
+
+  egl_image_ =
+      eglCreateImageKHR(gl::GLSurfaceEGL::GetGLDisplayEGL()->GetDisplay(),
+                        context_handle, EGL_GL_TEXTURE_2D_KHR,
+                        reinterpret_cast<EGLClientBuffer>(texture_id), nullptr);
+  if (egl_image_ == EGL_NO_IMAGE_KHR) {
+    LOG(ERROR) << "Error creating EGLImage: " << ui::GetLastEGLErrorString();
+    return false;
+  }
+
+  return true;
+}
+
+gfx::NativePixmapHandle GLImageGLTexture::ExportHandle() {
+  DCHECK_CALLED_ON_VALID_THREAD(thread_checker_);
+
+  // Must use Initialize.
+  if (egl_image_ == EGL_NO_IMAGE_KHR) {
+    LOG(ERROR) << "GLImageGLTexture is not initialized";
+    return gfx::NativePixmapHandle();
+  }
+
+  if (!has_image_dma_buf_export_) {
+    LOG(ERROR) << "Error no extension EGL_MESA_image_dma_buf_export";
+    return gfx::NativePixmapHandle();
+  }
+
+  int fourcc = 0;
+  int num_planes = 0;
+  EGLuint64KHR modifiers = 0;
+
+  if (!eglExportDMABUFImageQueryMESA(
+          gl::GLSurfaceEGL::GetGLDisplayEGL()->GetDisplay(), egl_image_,
+          &fourcc, &num_planes, &modifiers)) {
+    LOG(ERROR) << "Error querying EGLImage: " << ui::GetLastEGLErrorString();
+    return gfx::NativePixmapHandle();
+  }
+
+  if (num_planes <= 0 || num_planes > 4) {
+    LOG(ERROR) << "Invalid number of planes: " << num_planes;
+    return gfx::NativePixmapHandle();
+  }
+
+  gfx::BufferFormat format = GetBufferFormatFromFourCCFormat(fourcc);
+  if (format != format_) {
+    // A driver has returned a format different than what has been requested.
+    // This can happen if RGBX is implemented using RGBA. Otherwise there is
+    // a real mistake from the user and we have to fail.
+    if (GetInternalFormat() == GL_RGB &&
+        format != gfx::BufferFormat::RGBA_8888) {
+      LOG(ERROR) << "Invalid driver format: "
+                 << gfx::BufferFormatToString(format)
+                 << " for requested format: "
+                 << gfx::BufferFormatToString(format_);
+      return gfx::NativePixmapHandle();
+    }
+  }
+
+  std::vector<int> fds(num_planes);
+  std::vector<EGLint> strides(num_planes);
+  std::vector<EGLint> offsets(num_planes);
+
+  // It is specified for eglExportDMABUFImageMESA that the app is responsible
+  // for closing any fds retrieved.
+  if (!eglExportDMABUFImageMESA(
+          gl::GLSurfaceEGL::GetGLDisplayEGL()->GetDisplay(), egl_image_,
+          &fds[0], &strides[0], &offsets[0])) {
+    LOG(ERROR) << "Error exporting EGLImage: " << ui::GetLastEGLErrorString();
+    return gfx::NativePixmapHandle();
+  }
+
+  gfx::NativePixmapHandle handle{};
+  handle.modifier = modifiers;
+  for (int i = 0; i < num_planes; ++i) {
+    // Sanity check. In principle all the fds are meant to be valid when
+    // eglExportDMABUFImageMESA succeeds.
+    base::ScopedFD scoped_fd(fds[i]);
+    if (!scoped_fd.is_valid()) {
+      LOG(ERROR) << "Invalid dmabuf";
+      return gfx::NativePixmapHandle();
+    }
+
+    handle.planes.emplace_back(strides[i], offsets[i], 0 /* size opaque */,
+                               std::move(scoped_fd));
+  }
+
+  return handle;
+}
+
+void GLImageGLTexture::BindTexImage(unsigned target) {
+  DCHECK_CALLED_ON_VALID_THREAD(thread_checker_);
+
+  glEGLImageTargetTexture2DOES(target, egl_image_);
+}
+
+unsigned GLImageGLTexture::GetInternalFormat() {
+  return GLInternalFormat(format_);
+}
+
+}  // namespace media
diff --git a/media/gpu/vaapi/gl_image_gl_texture.h b/media/gpu/vaapi/gl_image_gl_texture.h
new file mode 100644
index 0000000..35015be
--- /dev/null
+++ b/media/gpu/vaapi/gl_image_gl_texture.h
@@ -0,0 +1,70 @@
+// Copyright 2023 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef MEDIA_GPU_VAAPI_GL_IMAGE_GL_TEXTURE_H_
+#define MEDIA_GPU_VAAPI_GL_IMAGE_GL_TEXTURE_H_
+
+#include <stdint.h>
+
+#include "base/memory/raw_ptr.h"
+#include "base/threading/thread_checker.h"
+#include "ui/gfx/geometry/size.h"
+#include "ui/gfx/native_pixmap_handle.h"
+#include "ui/gl/gl_image.h"
+
+namespace media {
+
+class VaapiPictureNativePixmapEgl;
+
+// GLImage subclass that is used by VaapiPictureNativePixmapEgl.
+// NOTE: No new usage of this class should be introduced, as it is in the
+// process of being eliminated.
+class GLImageGLTexture : public gl::GLImage {
+ private:
+  friend VaapiPictureNativePixmapEgl;
+
+  // Create an EGLImage from a given GL texture.
+  static scoped_refptr<GLImageGLTexture> CreateFromTexture(
+      const gfx::Size& size,
+      gfx::BufferFormat format,
+      uint32_t texture_id);
+
+  // Export the wrapped EGLImage to dmabuf fds.
+  gfx::NativePixmapHandle ExportHandle();
+
+ public:
+  // Allow usage from test contexts that are difficult to friend.
+  static scoped_refptr<GLImageGLTexture> CreateFromTextureForTesting(
+      const gfx::Size& size,
+      gfx::BufferFormat format,
+      uint32_t texture_id) {
+    return CreateFromTexture(size, format, texture_id);
+  }
+  gfx::NativePixmapHandle ExportHandleForTesting() { return ExportHandle(); }
+
+ private:
+  // Binds image to texture currently bound to |target|.
+  void BindTexImage(unsigned target);
+
+  ~GLImageGLTexture() override;
+
+  GLImageGLTexture(const gfx::Size& size, gfx::BufferFormat format);
+  // Create an EGLImage from a given GL texture. This EGLImage can be converted
+  // to an external resource to be shared with other client APIs.
+  bool InitializeFromTexture(uint32_t texture_id);
+
+  // Get the GL internal format of the image.
+  // It is aligned with glTexImage{2|3}D's parameter |internalformat|.
+  unsigned GetInternalFormat();
+
+  raw_ptr<void, DanglingUntriaged> egl_image_ /* EGLImageKHR */;
+  const gfx::Size size_;
+  THREAD_CHECKER(thread_checker_);
+  gfx::BufferFormat format_;
+  bool has_image_dma_buf_export_;
+};
+
+}  // namespace media
+
+#endif  // MEDIA_GPU_VAAPI_GL_IMAGE_GL_TEXTURE_H_
diff --git a/media/gpu/vaapi/vaapi_picture.cc b/media/gpu/vaapi/vaapi_picture.cc
new file mode 100644
index 0000000..101226a
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_picture.cc
@@ -0,0 +1,47 @@
+// Copyright 2014 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "media/gpu/vaapi/vaapi_picture.h"
+
+#include <va/va.h>
+
+#include "media/gpu/vaapi/vaapi_wrapper.h"
+#include "ui/gl/gl_bindings.h"
+#include "ui/gl/gl_implementation.h"
+
+namespace media {
+
+VaapiPicture::VaapiPicture(
+    scoped_refptr<VaapiWrapper> vaapi_wrapper,
+    const MakeGLContextCurrentCallback& make_context_current_cb,
+    const BindGLImageCallback& bind_image_cb,
+    int32_t picture_buffer_id,
+    const gfx::Size& size,
+    const gfx::Size& visible_size,
+    uint32_t texture_id,
+    uint32_t client_texture_id,
+    uint32_t texture_target)
+    : vaapi_wrapper_(std::move(vaapi_wrapper)),
+      make_context_current_cb_(make_context_current_cb),
+      bind_image_cb_(bind_image_cb),
+      size_(size),
+      visible_size_(visible_size),
+      texture_id_(texture_id),
+      client_texture_id_(client_texture_id),
+      texture_target_(texture_target),
+      picture_buffer_id_(picture_buffer_id) {}
+
+VaapiPicture::~VaapiPicture() {
+  DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
+}
+
+bool VaapiPicture::AllowOverlay() const {
+  return false;
+}
+
+VASurfaceID VaapiPicture::va_surface_id() const {
+  return VA_INVALID_ID;
+}
+
+}  // namespace media
diff --git a/media/gpu/vaapi/vaapi_picture.h b/media/gpu/vaapi/vaapi_picture.h
new file mode 100644
index 0000000..50c944c
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_picture.h
@@ -0,0 +1,88 @@
+// Copyright 2014 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+//
+// This file contains an interface of output pictures for the Vaapi
+// video decoder. This is implemented by different window system
+// (X11/Ozone) and used by VaapiVideoDecodeAccelerator to produce
+// output pictures.
+
+#ifndef MEDIA_GPU_VAAPI_VAAPI_PICTURE_H_
+#define MEDIA_GPU_VAAPI_VAAPI_PICTURE_H_
+
+#include <stdint.h>
+
+#include "base/memory/scoped_refptr.h"
+#include "base/sequence_checker.h"
+#include "media/gpu/gpu_video_decode_accelerator_helpers.h"
+#include "media/gpu/media_gpu_export.h"
+#include "media/gpu/vaapi/vaapi_status.h"
+#include "ui/gfx/geometry/size.h"
+#include "ui/gfx/gpu_memory_buffer.h"
+
+namespace media {
+
+using VASurfaceID = unsigned int;
+
+class VASurface;
+class VaapiWrapper;
+
+// Picture is native pixmap abstraction (X11/Ozone).
+class MEDIA_GPU_EXPORT VaapiPicture {
+ public:
+  VaapiPicture(const VaapiPicture&) = delete;
+  VaapiPicture& operator=(const VaapiPicture&) = delete;
+
+  virtual ~VaapiPicture();
+
+  // Uses the buffer of |format|, pointed to by |gpu_memory_buffer_handle| as
+  // the backing storage for this picture. This takes ownership of the handle
+  // and will close it even on failure. Return true on success, false otherwise.
+  virtual bool ImportGpuMemoryBufferHandle(
+      gfx::BufferFormat format,
+      gfx::GpuMemoryBufferHandle gpu_memory_buffer_handle) = 0;
+
+  // Allocates a buffer of |format| to use as backing storage for this picture.
+  virtual VaapiStatus Allocate(gfx::BufferFormat format) = 0;
+
+  int32_t picture_buffer_id() const { return picture_buffer_id_; }
+
+  virtual bool AllowOverlay() const;
+
+  // Downloads |va_surface| into the picture, potentially scaling it if needed.
+  virtual bool DownloadFromSurface(scoped_refptr<VASurface> va_surface) = 0;
+
+  // Returns the associated VASurfaceID, if any, or VA_INVALID_ID.
+  virtual VASurfaceID va_surface_id() const;
+
+ protected:
+  VaapiPicture(scoped_refptr<VaapiWrapper> vaapi_wrapper,
+               const MakeGLContextCurrentCallback& make_context_current_cb,
+               const BindGLImageCallback& bind_image_cb,
+               int32_t picture_buffer_id,
+               const gfx::Size& size,
+               const gfx::Size& visible_size,
+               uint32_t texture_id,
+               uint32_t client_texture_id,
+               uint32_t texture_target);
+
+  const scoped_refptr<VaapiWrapper> vaapi_wrapper_;
+
+  const MakeGLContextCurrentCallback make_context_current_cb_;
+  const BindGLImageCallback bind_image_cb_;
+
+  const gfx::Size size_;
+  const gfx::Size visible_size_;
+  const uint32_t texture_id_;
+  const uint32_t client_texture_id_;
+  const uint32_t texture_target_;
+
+  SEQUENCE_CHECKER(sequence_checker_);
+
+ private:
+  const int32_t picture_buffer_id_;
+};
+
+}  // namespace media
+
+#endif  // MEDIA_GPU_VAAPI_VAAPI_PICTURE_H_
diff --git a/media/gpu/vaapi/vaapi_picture_factory.cc b/media/gpu/vaapi/vaapi_picture_factory.cc
new file mode 100644
index 0000000..5dadd7c
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_picture_factory.cc
@@ -0,0 +1,168 @@
+// Copyright 2017 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "media/gpu/vaapi/vaapi_picture_factory.h"
+
+#include "base/containers/contains.h"
+#include "build/build_config.h"
+#include "media/gpu/vaapi/vaapi_wrapper.h"
+#include "media/video/picture.h"
+#include "ui/gl/gl_bindings.h"
+
+#if BUILDFLAG(IS_OZONE)
+#include "media/gpu/vaapi/vaapi_picture_native_pixmap_ozone.h"
+#endif  // BUILDFLAG(IS_OZONE)
+#if BUILDFLAG(USE_VAAPI_X11)
+#include "media/gpu/vaapi/vaapi_picture_native_pixmap_angle.h"
+#endif  // BUILDFLAG(USE_VAAPI_X11)
+#if defined(USE_EGL)
+#include "media/gpu/vaapi/vaapi_picture_native_pixmap_egl.h"
+#endif
+
+namespace media {
+
+namespace {
+
+template <typename PictureType>
+std::unique_ptr<VaapiPicture> CreateVaapiPictureNativeImpl(
+    scoped_refptr<VaapiWrapper> vaapi_wrapper,
+    const MakeGLContextCurrentCallback& make_context_current_cb,
+    const BindGLImageCallback& bind_image_cb,
+    const PictureBuffer& picture_buffer,
+    const gfx::Size& visible_size,
+    uint32_t client_texture_id,
+    uint32_t service_texture_id) {
+  return std::make_unique<PictureType>(
+      std::move(vaapi_wrapper), make_context_current_cb, bind_image_cb,
+      picture_buffer.id(), picture_buffer.size(), visible_size,
+      service_texture_id, client_texture_id, picture_buffer.texture_target());
+}
+
+}  // namespace
+
+VaapiPictureFactory::VaapiPictureFactory() {
+  vaapi_impl_pairs_.insert(
+      std::make_pair(gl::kGLImplementationEGLGLES2,
+                     VaapiPictureFactory::kVaapiImplementationDrm));
+#if BUILDFLAG(USE_VAAPI_X11)
+  vaapi_impl_pairs_.insert(
+      std::make_pair(gl::kGLImplementationEGLANGLE,
+                     VaapiPictureFactory::kVaapiImplementationAngle));
+#elif BUILDFLAG(IS_OZONE)
+  vaapi_impl_pairs_.insert(
+      std::make_pair(gl::kGLImplementationEGLANGLE,
+                     VaapiPictureFactory::kVaapiImplementationDrm));
+#endif
+
+  DeterminePictureCreationAndDownloadingMechanism();
+}
+
+VaapiPictureFactory::~VaapiPictureFactory() = default;
+
+std::unique_ptr<VaapiPicture> VaapiPictureFactory::Create(
+    scoped_refptr<VaapiWrapper> vaapi_wrapper,
+    const MakeGLContextCurrentCallback& make_context_current_cb,
+    const BindGLImageCallback& bind_image_cb,
+    const PictureBuffer& picture_buffer,
+    const gfx::Size& visible_size) {
+  // ARC++ sends |picture_buffer| with no texture_target().
+  DCHECK(picture_buffer.texture_target() == GetGLTextureTarget() ||
+         picture_buffer.texture_target() == 0u);
+
+  // |client_texture_ids| and |service_texture_ids| are empty from ARC++.
+  const uint32_t client_texture_id =
+      !picture_buffer.client_texture_ids().empty()
+          ? picture_buffer.client_texture_ids()[0]
+          : 0;
+  const uint32_t service_texture_id =
+      !picture_buffer.service_texture_ids().empty()
+          ? picture_buffer.service_texture_ids()[0]
+          : 0;
+
+  return CreateVaapiPictureNative(vaapi_wrapper, make_context_current_cb,
+                                  bind_image_cb, picture_buffer, visible_size,
+                                  client_texture_id, service_texture_id);
+}
+
+VaapiPictureFactory::VaapiImplementation
+VaapiPictureFactory::GetVaapiImplementation(gl::GLImplementation gl_impl) {
+  if (base::Contains(vaapi_impl_pairs_, gl_impl))
+    return vaapi_impl_pairs_[gl_impl];
+  return kVaapiImplementationNone;
+}
+
+uint32_t VaapiPictureFactory::GetGLTextureTarget() {
+#if BUILDFLAG(USE_VAAPI_X11)
+  return GL_TEXTURE_2D;
+#else
+  return GL_TEXTURE_EXTERNAL_OES;
+#endif
+}
+
+gfx::BufferFormat VaapiPictureFactory::GetBufferFormat() {
+#if BUILDFLAG(USE_VAAPI_X11)
+  return gfx::BufferFormat::RGBX_8888;
+#else
+  return gfx::BufferFormat::YUV_420_BIPLANAR;
+#endif
+}
+
+void VaapiPictureFactory::DeterminePictureCreationAndDownloadingMechanism() {
+  switch (GetVaapiImplementation(gl::GetGLImplementation())) {
+#if BUILDFLAG(IS_OZONE)
+    // We can be called without GL initialized, which is valid if we use Ozone.
+    case kVaapiImplementationNone:
+      create_picture_cb_ = base::BindRepeating(
+          &CreateVaapiPictureNativeImpl<VaapiPictureNativePixmapOzone>);
+      needs_vpp_for_downloading_ = true;
+      break;
+#endif  // BUILDFLAG(IS_OZONE)
+#if BUILDFLAG(USE_VAAPI_X11)
+    case kVaapiImplementationAngle:
+      create_picture_cb_ = base::BindRepeating(
+          &CreateVaapiPictureNativeImpl<VaapiPictureNativePixmapAngle>);
+      // Neither VaapiTFPPicture or VaapiPictureNativePixmapAngle needs the VPP.
+      needs_vpp_for_downloading_ = false;
+      break;
+#endif  // BUILDFLAG(USE_VAAPI_X11)
+    case kVaapiImplementationDrm:
+#if BUILDFLAG(IS_OZONE)
+      create_picture_cb_ = base::BindRepeating(
+          &CreateVaapiPictureNativeImpl<VaapiPictureNativePixmapOzone>);
+      needs_vpp_for_downloading_ = true;
+      break;
+#elif defined(USE_EGL)
+      create_picture_cb_ = base::BindRepeating(
+          &CreateVaapiPictureNativeImpl<VaapiPictureNativePixmapEgl>);
+      needs_vpp_for_downloading_ = true;
+      break;
+#else
+      // ozone or egl must be used to use the DRM implementation.
+      [[fallthrough]];
+#endif
+    default:
+      NOTREACHED();
+      break;
+  }
+}
+
+bool VaapiPictureFactory::NeedsProcessingPipelineForDownloading() const {
+  return needs_vpp_for_downloading_;
+}
+
+std::unique_ptr<VaapiPicture> VaapiPictureFactory::CreateVaapiPictureNative(
+    scoped_refptr<VaapiWrapper> vaapi_wrapper,
+    const MakeGLContextCurrentCallback& make_context_current_cb,
+    const BindGLImageCallback& bind_image_cb,
+    const PictureBuffer& picture_buffer,
+    const gfx::Size& visible_size,
+    uint32_t client_texture_id,
+    uint32_t service_texture_id) {
+  CHECK(create_picture_cb_);
+  return create_picture_cb_.Run(
+      std::move(vaapi_wrapper), make_context_current_cb, bind_image_cb,
+      picture_buffer, visible_size, client_texture_id, service_texture_id);
+}
+
+}  // namespace media
diff --git a/media/gpu/vaapi/vaapi_picture_factory.h b/media/gpu/vaapi/vaapi_picture_factory.h
new file mode 100644
index 0000000..213c030
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_picture_factory.h
@@ -0,0 +1,91 @@
+// Copyright 2017 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef MEDIA_GPU_VAAPI_VAAPI_PICTURE_FACTORY_H_
+#define MEDIA_GPU_VAAPI_VAAPI_PICTURE_FACTORY_H_
+
+#include <stdint.h>
+
+#include "base/memory/scoped_refptr.h"
+#include "media/gpu/vaapi/vaapi_picture.h"
+#include "ui/gfx/geometry/size.h"
+#include "ui/gl/gl_implementation.h"
+
+namespace media {
+
+class PictureBuffer;
+class VaapiWrapper;
+
+using CreatePictureCB = base::RepeatingCallback<std::unique_ptr<VaapiPicture>(
+    scoped_refptr<VaapiWrapper>,
+    const MakeGLContextCurrentCallback&,
+    const BindGLImageCallback&,
+    const PictureBuffer&,
+    const gfx::Size&,
+    uint32_t,
+    uint32_t)>;
+
+// Factory of platform dependent VaapiPictures.
+class MEDIA_GPU_EXPORT VaapiPictureFactory {
+ public:
+  enum VaapiImplementation {
+    kVaapiImplementationNone = 0,
+    kVaapiImplementationDrm,
+    kVaapiImplementationAngle,
+  };
+
+  VaapiPictureFactory();
+
+  VaapiPictureFactory(const VaapiPictureFactory&) = delete;
+  VaapiPictureFactory& operator=(const VaapiPictureFactory&) = delete;
+
+  virtual ~VaapiPictureFactory();
+
+  // Creates a VaapiPicture of picture_buffer.size() associated with
+  // picture_buffer.id().
+  virtual std::unique_ptr<VaapiPicture> Create(
+      scoped_refptr<VaapiWrapper> vaapi_wrapper,
+      const MakeGLContextCurrentCallback& make_context_current_cb,
+      const BindGLImageCallback& bind_image_cb,
+      const PictureBuffer& picture_buffer,
+      const gfx::Size& visible_size);
+
+  // Return the type of the VaapiPicture implementation for the given GL
+  // implementation.
+  VaapiImplementation GetVaapiImplementation(gl::GLImplementation gl_impl);
+
+  // Determines whether the DownloadFromSurface() method of the VaapiPictures
+  // created by this factory requires a processing pipeline VaapiWrapper.
+  bool NeedsProcessingPipelineForDownloading() const;
+
+  // Gets the texture target used to bind EGLImages (either GL_TEXTURE_2D on X11
+  // or GL_TEXTURE_EXTERNAL_OES on DRM).
+  uint32_t GetGLTextureTarget();
+
+  // Buffer format to use for output buffers backing PictureBuffers. This is
+  // the format decoded frames in VASurfaces are converted into.
+  gfx::BufferFormat GetBufferFormat();
+
+  std::unique_ptr<VaapiPicture> CreateVaapiPictureNative(
+      scoped_refptr<VaapiWrapper> vaapi_wrapper,
+      const MakeGLContextCurrentCallback& make_context_current_cb,
+      const BindGLImageCallback& bind_image_cb,
+      const PictureBuffer& picture_buffer,
+      const gfx::Size& visible_size,
+      uint32_t client_texture_id,
+      uint32_t service_texture_id);
+
+  std::map<gl::GLImplementation, VaapiPictureFactory::VaapiImplementation>
+      vaapi_impl_pairs_;
+
+ private:
+  void DeterminePictureCreationAndDownloadingMechanism();
+
+  CreatePictureCB create_picture_cb_;
+  bool needs_vpp_for_downloading_ = false;
+};
+
+}  // namespace media
+
+#endif  // MEDIA_GPU_VAAPI_VAAPI_PICTURE_FACTORY_H_
diff --git a/media/gpu/vaapi/vaapi_picture_native_pixmap.cc b/media/gpu/vaapi/vaapi_picture_native_pixmap.cc
new file mode 100644
index 0000000..6c40d52
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_picture_native_pixmap.cc
@@ -0,0 +1,49 @@
+// Copyright 2018 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "media/gpu/vaapi/vaapi_picture_native_pixmap.h"
+
+#include "media/gpu/vaapi/va_surface.h"
+#include "media/gpu/vaapi/vaapi_wrapper.h"
+
+namespace media {
+
+VaapiPictureNativePixmap::VaapiPictureNativePixmap(
+    scoped_refptr<VaapiWrapper> vaapi_wrapper,
+    const MakeGLContextCurrentCallback& make_context_current_cb,
+    const BindGLImageCallback& bind_image_cb,
+    int32_t picture_buffer_id,
+    const gfx::Size& size,
+    const gfx::Size& visible_size,
+    uint32_t texture_id,
+    uint32_t client_texture_id,
+    uint32_t texture_target)
+    : VaapiPicture(std::move(vaapi_wrapper),
+                   make_context_current_cb,
+                   bind_image_cb,
+                   picture_buffer_id,
+                   size,
+                   visible_size,
+                   texture_id,
+                   client_texture_id,
+                   texture_target) {}
+
+VaapiPictureNativePixmap::~VaapiPictureNativePixmap() = default;
+
+bool VaapiPictureNativePixmap::DownloadFromSurface(
+    scoped_refptr<VASurface> va_surface) {
+  DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
+  return vaapi_wrapper_->BlitSurface(*va_surface, *va_surface_);
+}
+
+bool VaapiPictureNativePixmap::AllowOverlay() const {
+  DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
+  return true;
+}
+
+VASurfaceID VaapiPictureNativePixmap::va_surface_id() const {
+  return va_surface_->id();
+}
+
+}  // namespace media
diff --git a/media/gpu/vaapi/vaapi_picture_native_pixmap.h b/media/gpu/vaapi/vaapi_picture_native_pixmap.h
new file mode 100644
index 0000000..ec5d5e1
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_picture_native_pixmap.h
@@ -0,0 +1,50 @@
+// Copyright 2018 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef MEDIA_GPU_VAAPI_VAAPI_PICTURE_NATIVE_PIXMAP_H_
+#define MEDIA_GPU_VAAPI_VAAPI_PICTURE_NATIVE_PIXMAP_H_
+
+#include <stdint.h>
+
+#include "base/memory/scoped_refptr.h"
+#include "media/gpu/vaapi/va_surface.h"
+#include "media/gpu/vaapi/vaapi_picture.h"
+#include "ui/gfx/geometry/size.h"
+
+namespace media {
+
+class VaapiWrapper;
+
+// Implementation of VaapiPicture based on NativePixmaps.
+class VaapiPictureNativePixmap : public VaapiPicture {
+ public:
+  VaapiPictureNativePixmap(
+      scoped_refptr<VaapiWrapper> vaapi_wrapper,
+      const MakeGLContextCurrentCallback& make_context_current_cb,
+      const BindGLImageCallback& bind_image_cb_,
+      int32_t picture_buffer_id,
+      const gfx::Size& size,
+      const gfx::Size& visible_size,
+      uint32_t texture_id,
+      uint32_t client_texture_id,
+      uint32_t texture_target);
+
+  VaapiPictureNativePixmap(const VaapiPictureNativePixmap&) = delete;
+  VaapiPictureNativePixmap& operator=(const VaapiPictureNativePixmap&) = delete;
+
+  ~VaapiPictureNativePixmap() override;
+
+  // VaapiPicture implementation.
+  bool DownloadFromSurface(scoped_refptr<VASurface> va_surface) override;
+  bool AllowOverlay() const override;
+  VASurfaceID va_surface_id() const override;
+
+ protected:
+  // VASurface used to transfer from the decoder's pixel format.
+  scoped_refptr<VASurface> va_surface_;
+};
+
+}  // namespace media
+
+#endif  // MEDIA_GPU_VAAPI_VAAPI_PICTURE_NATIVE_PIXMAP_H_
diff --git a/media/gpu/vaapi/vaapi_picture_native_pixmap_angle.cc b/media/gpu/vaapi/vaapi_picture_native_pixmap_angle.cc
new file mode 100644
index 0000000..1a0be4d
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_picture_native_pixmap_angle.cc
@@ -0,0 +1,161 @@
+// Copyright 2020 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "media/gpu/vaapi/vaapi_picture_native_pixmap_angle.h"
+
+#include "media/gpu/vaapi/gl_image_egl_pixmap.h"
+#include "media/gpu/vaapi/va_surface.h"
+#include "media/gpu/vaapi/vaapi_status.h"
+#include "media/gpu/vaapi/vaapi_wrapper.h"
+#include "ui/gfx/x/connection.h"
+#include "ui/gfx/x/future.h"
+#include "ui/gfx/x/xproto.h"
+#include "ui/gl/gl_bindings.h"
+#include "ui/gl/scoped_binders.h"
+
+namespace media {
+
+namespace {
+
+x11::Pixmap CreatePixmap(const gfx::Size& size) {
+  auto* connection = x11::Connection::Get();
+  if (!connection->Ready())
+    return x11::Pixmap::None;
+
+  auto root = connection->default_root();
+
+  uint8_t depth = 0;
+  if (auto reply = connection->GetGeometry(root).Sync())
+    depth = reply->depth;
+  else
+    return x11::Pixmap::None;
+
+  // TODO(tmathmeyer) should we use the depth from libva instead of root window?
+  auto pixmap = connection->GenerateId<x11::Pixmap>();
+  uint16_t pixmap_width, pixmap_height;
+  if (!base::CheckedNumeric<int>(size.width()).AssignIfValid(&pixmap_width) ||
+      !base::CheckedNumeric<int>(size.height()).AssignIfValid(&pixmap_height)) {
+    return x11::Pixmap::None;
+  }
+  auto req = connection->CreatePixmap(
+      {depth, pixmap, root, pixmap_width, pixmap_height});
+  if (req.Sync().error)
+    pixmap = x11::Pixmap::None;
+  return pixmap;
+}
+
+}  // namespace
+
+VaapiPictureNativePixmapAngle::VaapiPictureNativePixmapAngle(
+    scoped_refptr<VaapiWrapper> vaapi_wrapper,
+    const MakeGLContextCurrentCallback& make_context_current_cb,
+    const BindGLImageCallback& bind_image_cb,
+    int32_t picture_buffer_id,
+    const gfx::Size& size,
+    const gfx::Size& visible_size,
+    uint32_t service_texture_id,
+    uint32_t client_texture_id,
+    uint32_t texture_target)
+    : VaapiPictureNativePixmap(std::move(vaapi_wrapper),
+                               make_context_current_cb,
+                               bind_image_cb,
+                               picture_buffer_id,
+                               size,
+                               visible_size,
+                               service_texture_id,
+                               client_texture_id,
+                               texture_target) {
+  DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
+
+  // Check that they're both not 0
+  DCHECK(service_texture_id);
+  DCHECK(client_texture_id);
+}
+
+VaapiPictureNativePixmapAngle::~VaapiPictureNativePixmapAngle() {
+  DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
+  if (gl_image_ && make_context_current_cb_.Run()) {
+    gl_image_->ReleaseEGLImage();
+    DCHECK_EQ(glGetError(), static_cast<GLenum>(GL_NO_ERROR));
+  }
+
+  if (x_pixmap_ != x11::Pixmap::None)
+    x11::Connection::Get()->FreePixmap({x_pixmap_});
+
+  // Reset |va_surface_| before |gl_image_| to preserve the order of destruction
+  // before the refactoring done in
+  // https://chromium-review.googlesource.com/c/chromium/src/+/4025005.
+  // TODO(crbug.com/1366367): Determine whether preserving this order matters
+  // and remove these calls if not.
+  va_surface_.reset();
+  gl_image_.reset();
+}
+
+VaapiStatus VaapiPictureNativePixmapAngle::Allocate(gfx::BufferFormat format) {
+  DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
+  if (!(texture_id_ || client_texture_id_))
+    return VaapiStatus::Codes::kNoTexture;
+
+  if (!make_context_current_cb_ || !make_context_current_cb_.Run())
+    return VaapiStatus::Codes::kBadContext;
+
+  auto image = base::WrapRefCounted<GLImageEGLPixmap>(
+      new GLImageEGLPixmap(visible_size_));
+  if (!image)
+    return VaapiStatus::Codes::kNoImage;
+
+  x_pixmap_ = CreatePixmap(visible_size_);
+  if (x_pixmap_ == x11::Pixmap::None)
+    return VaapiStatus::Codes::kNoPixmap;
+
+  if (!image->Initialize(x_pixmap_))
+    return VaapiStatus::Codes::kFailedToInitializeImage;
+
+  gl::ScopedTextureBinder texture_binder(texture_target_, texture_id_);
+  if (!image->BindTexImage(texture_target_))
+    return VaapiStatus::Codes::kFailedToBindTexture;
+
+  gl_image_ = image;
+
+  DCHECK(bind_image_cb_);
+  if (!bind_image_cb_.Run(client_texture_id_, texture_target_, gl_image_)) {
+    return VaapiStatus::Codes::kFailedToBindImage;
+  }
+
+  return VaapiStatus::Codes::kOk;
+}
+
+bool VaapiPictureNativePixmapAngle::ImportGpuMemoryBufferHandle(
+    gfx::BufferFormat format,
+    gfx::GpuMemoryBufferHandle gpu_memory_buffer_handle) {
+  NOTREACHED_NORETURN();
+}
+
+bool VaapiPictureNativePixmapAngle::DownloadFromSurface(
+    scoped_refptr<VASurface> va_surface) {
+  DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
+
+  if (!make_context_current_cb_ || !make_context_current_cb_.Run())
+    return false;
+
+  DCHECK(texture_id_);
+  gl::ScopedTextureBinder texture_binder(texture_target_, texture_id_);
+
+  // GL needs to re-bind the texture after the pixmap content is updated so that
+  // the compositor sees the updated contents (we found this out experimentally)
+  gl_image_->ReleaseEGLImage();
+
+  DCHECK(gfx::Rect(va_surface->size()).Contains(gfx::Rect(visible_size_)));
+  if (!vaapi_wrapper_->PutSurfaceIntoPixmap(va_surface->id(), x_pixmap_,
+                                            visible_size_)) {
+    return false;
+  }
+  return gl_image_->BindTexImage(texture_target_);
+}
+
+VASurfaceID VaapiPictureNativePixmapAngle::va_surface_id() const {
+  return VA_INVALID_ID;
+}
+
+}  // namespace media
diff --git a/media/gpu/vaapi/vaapi_picture_native_pixmap_angle.h b/media/gpu/vaapi/vaapi_picture_native_pixmap_angle.h
new file mode 100644
index 0000000..157360a
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_picture_native_pixmap_angle.h
@@ -0,0 +1,62 @@
+// Copyright 2020 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef MEDIA_GPU_VAAPI_VAAPI_PICTURE_NATIVE_PIXMAP_ANGLE_H_
+#define MEDIA_GPU_VAAPI_VAAPI_PICTURE_NATIVE_PIXMAP_ANGLE_H_
+
+#include <stdint.h>
+
+#include "base/memory/scoped_refptr.h"
+#include "base/memory/weak_ptr.h"
+#include "media/gpu/vaapi/vaapi_picture_native_pixmap.h"
+#include "ui/gfx/buffer_types.h"
+#include "ui/gfx/geometry/size.h"
+#include "ui/gfx/x/xproto.h"
+#include "ui/gl/gl_bindings.h"
+
+namespace media {
+
+class GLImageEGLPixmap;
+class VaapiWrapper;
+
+// Implementation of VaapiPictureNativePixmap for ANGLE backends.
+class VaapiPictureNativePixmapAngle : public VaapiPictureNativePixmap {
+ public:
+  VaapiPictureNativePixmapAngle(
+      scoped_refptr<VaapiWrapper> vaapi_wrapper,
+      const MakeGLContextCurrentCallback& make_context_current_cb,
+      const BindGLImageCallback& bind_image_cb_,
+      int32_t picture_buffer_id,
+      const gfx::Size& size,
+      const gfx::Size& visible_size,
+      uint32_t texture_id,
+      uint32_t client_texture_id,
+      uint32_t texture_target);
+
+  VaapiPictureNativePixmapAngle(const VaapiPictureNativePixmapAngle&) = delete;
+  VaapiPictureNativePixmapAngle& operator=(
+      const VaapiPictureNativePixmapAngle&) = delete;
+
+  ~VaapiPictureNativePixmapAngle() override;
+
+  // VaapiPicture implementation.
+  VaapiStatus Allocate(gfx::BufferFormat format) override;
+  bool ImportGpuMemoryBufferHandle(
+      gfx::BufferFormat format,
+      gfx::GpuMemoryBufferHandle gpu_memory_buffer_handle) override;
+  bool DownloadFromSurface(scoped_refptr<VASurface> va_surface) override;
+
+  // This native pixmap implementation never instantiates its own VASurfaces.
+  VASurfaceID va_surface_id() const override;
+
+ private:
+  x11::Pixmap x_pixmap_ = x11::Pixmap::None;
+
+  // GLImage bound to the GL textures used by the VDA client.
+  scoped_refptr<GLImageEGLPixmap> gl_image_;
+};
+
+}  // namespace media
+
+#endif  // MEDIA_GPU_VAAPI_VAAPI_PICTURE_NATIVE_PIXMAP_ANGLE_H_
diff --git a/media/gpu/vaapi/vaapi_picture_native_pixmap_egl.cc b/media/gpu/vaapi/vaapi_picture_native_pixmap_egl.cc
new file mode 100644
index 0000000..a28f3ff
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_picture_native_pixmap_egl.cc
@@ -0,0 +1,140 @@
+// Copyright 2018 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "media/gpu/vaapi/vaapi_picture_native_pixmap_egl.h"
+
+#include "base/file_descriptor_posix.h"
+#include "gpu/command_buffer/common/gpu_memory_buffer_support.h"
+#include "media/gpu/vaapi/gl_image_gl_texture.h"
+#include "media/gpu/vaapi/va_surface.h"
+#include "media/gpu/vaapi/vaapi_status.h"
+#include "media/gpu/vaapi/vaapi_wrapper.h"
+#include "ui/gfx/linux/native_pixmap_dmabuf.h"
+#include "ui/gfx/native_pixmap.h"
+#include "ui/gl/gl_bindings.h"
+#include "ui/gl/scoped_binders.h"
+
+namespace media {
+
+VaapiPictureNativePixmapEgl::VaapiPictureNativePixmapEgl(
+    scoped_refptr<VaapiWrapper> vaapi_wrapper,
+    const MakeGLContextCurrentCallback& make_context_current_cb,
+    const BindGLImageCallback& bind_image_cb,
+    int32_t picture_buffer_id,
+    const gfx::Size& visible_size,
+    const gfx::Size& size,
+    uint32_t texture_id,
+    uint32_t client_texture_id,
+    uint32_t texture_target)
+    : VaapiPictureNativePixmap(std::move(vaapi_wrapper),
+                               make_context_current_cb,
+                               bind_image_cb,
+                               picture_buffer_id,
+                               size,
+                               visible_size,
+                               texture_id,
+                               client_texture_id,
+                               texture_target) {
+  DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
+  DCHECK(texture_id);
+  DCHECK(client_texture_id);
+}
+
+VaapiPictureNativePixmapEgl::~VaapiPictureNativePixmapEgl() {
+  DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
+  if (gl_image_ && make_context_current_cb_.Run()) {
+    DCHECK_EQ(glGetError(), static_cast<GLenum>(GL_NO_ERROR));
+  }
+
+  // Reset |va_surface_| before |gl_image_| to preserve the order of destruction
+  // before the refactoring done in
+  // https://chromium-review.googlesource.com/c/chromium/src/+/4025005.
+  // TODO(crbug.com/1366367): Determine whether preserving this order matters
+  // and remove these calls if not.
+  va_surface_.reset();
+  gl_image_.reset();
+}
+
+VaapiStatus VaapiPictureNativePixmapEgl::Initialize(
+    scoped_refptr<gfx::NativePixmap> pixmap) {
+  DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
+  DCHECK(pixmap);
+  DCHECK(pixmap->AreDmaBufFdsValid());
+
+  // Create a |va_surface_| from dmabuf fds (pixmap->GetDmaBufFd)
+  va_surface_ = vaapi_wrapper_->CreateVASurfaceForPixmap(std::move(pixmap));
+  if (!va_surface_) {
+    LOG(ERROR) << "Failed creating VASurface for NativePixmap";
+    return VaapiStatus::Codes::kNoSurface;
+  }
+
+  if (bind_image_cb_ &&
+      !bind_image_cb_.Run(client_texture_id_, texture_target_, gl_image_)) {
+    LOG(ERROR) << "Failed to bind client_texture_id";
+    return VaapiStatus::Codes::kFailedToBindImage;
+  }
+  return VaapiStatus::Codes::kOk;
+}
+
+VaapiStatus VaapiPictureNativePixmapEgl::Allocate(gfx::BufferFormat format) {
+  DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
+
+  // Export the gl texture as dmabuf.
+  if (make_context_current_cb_ && !make_context_current_cb_.Run())
+    return VaapiStatus::Codes::kBadContext;
+
+  // TODO(b/220336463): plumb the right color space.
+  auto image =
+      GLImageGLTexture::CreateFromTexture(visible_size_, format, texture_id_);
+  // Create an EGLImage from a gl texture
+  if (!image) {
+    DLOG(ERROR) << "Failed to initialize eglimage from texture id: "
+                << texture_id_;
+    return VaapiStatus::Codes::kFailedToInitializeImage;
+  }
+
+  // Export the EGLImage as dmabuf.
+  gfx::NativePixmapHandle native_pixmap_handle = image->ExportHandle();
+  if (!native_pixmap_handle.planes.size()) {
+    DLOG(ERROR) << "Failed to export EGLImage as dmabuf fds";
+    return VaapiStatus::Codes::kFailedToExportImage;
+  }
+
+  if (size_.width() > static_cast<int>(native_pixmap_handle.planes[0].stride) ||
+      size_.GetArea() > static_cast<int>(native_pixmap_handle.planes[0].size)) {
+    DLOG(ERROR) << "EGLImage (stride=" << native_pixmap_handle.planes[0].stride
+                << ", size=" << native_pixmap_handle.planes[0].size
+                << "is smaller than size_=" << size_.ToString();
+    return VaapiStatus::Codes::kBadImageSize;
+  }
+
+  // Convert NativePixmapHandle to NativePixmapDmaBuf.
+  scoped_refptr<gfx::NativePixmap> native_pixmap_dmabuf(
+      new gfx::NativePixmapDmaBuf(size_, format,
+                                  std::move(native_pixmap_handle)));
+  if (!native_pixmap_dmabuf->AreDmaBufFdsValid()) {
+    DLOG(ERROR) << "Invalid dmabuf fds";
+    return VaapiStatus::Codes::kNoBufferHandle;
+  }
+
+  image->BindTexImage(texture_target_);
+
+  // The |va_surface_| created from |native_pixmap_dmabuf| shares the ownership
+  // of the buffer. So the only reason to keep a reference on the image is
+  // because the GPU service needs to track this image as it will be attached
+  // to a client texture.
+  gl_image_ = image;
+
+  return Initialize(std::move(native_pixmap_dmabuf));
+}
+
+bool VaapiPictureNativePixmapEgl::ImportGpuMemoryBufferHandle(
+    gfx::BufferFormat format,
+    gfx::GpuMemoryBufferHandle gpu_memory_buffer_handle) {
+  DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
+  NOTIMPLEMENTED();
+  return false;
+}
+
+}  // namespace media
diff --git a/media/gpu/vaapi/vaapi_picture_native_pixmap_egl.h b/media/gpu/vaapi/vaapi_picture_native_pixmap_egl.h
new file mode 100644
index 0000000..da0ca0e
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_picture_native_pixmap_egl.h
@@ -0,0 +1,61 @@
+// Copyright 2018 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef MEDIA_GPU_VAAPI_VAAPI_PICTURE_NATIVE_PIXMAP_EGL_H_
+#define MEDIA_GPU_VAAPI_VAAPI_PICTURE_NATIVE_PIXMAP_EGL_H_
+
+#include <stdint.h>
+
+#include "base/memory/scoped_refptr.h"
+#include "base/memory/weak_ptr.h"
+#include "media/gpu/vaapi/vaapi_picture_native_pixmap.h"
+#include "ui/gfx/buffer_types.h"
+#include "ui/gfx/geometry/size.h"
+
+namespace gfx {
+class NativePixmap;
+}  // namespace gfx
+
+namespace media {
+
+class GLImageGLTexture;
+class VaapiWrapper;
+
+// Implementation of VaapiPictureNativePixmap for EGL backends, see
+// https://crbug.com/785201.
+class VaapiPictureNativePixmapEgl : public VaapiPictureNativePixmap {
+ public:
+  VaapiPictureNativePixmapEgl(
+      scoped_refptr<VaapiWrapper> vaapi_wrapper,
+      const MakeGLContextCurrentCallback& make_context_current_cb,
+      const BindGLImageCallback& bind_image_cb_,
+      int32_t picture_buffer_id,
+      const gfx::Size& size,
+      const gfx::Size& visible_size,
+      uint32_t texture_id,
+      uint32_t client_texture_id,
+      uint32_t texture_target);
+
+  VaapiPictureNativePixmapEgl(const VaapiPictureNativePixmapEgl&) = delete;
+  VaapiPictureNativePixmapEgl& operator=(const VaapiPictureNativePixmapEgl&) =
+      delete;
+
+  ~VaapiPictureNativePixmapEgl() override;
+
+  // VaapiPicture implementation.
+  VaapiStatus Allocate(gfx::BufferFormat format) override;
+  bool ImportGpuMemoryBufferHandle(
+      gfx::BufferFormat format,
+      gfx::GpuMemoryBufferHandle gpu_memory_buffer_handle) override;
+
+ private:
+  VaapiStatus Initialize(scoped_refptr<gfx::NativePixmap> pixmap);
+
+  // GLImage bound to the GL textures used by the VDA client.
+  scoped_refptr<GLImageGLTexture> gl_image_;
+};
+
+}  // namespace media
+
+#endif  // MEDIA_GPU_VAAPI_VAAPI_PICTURE_NATIVE_PIXMAP_EGL_H_
diff --git a/media/gpu/vaapi/vaapi_picture_native_pixmap_ozone.cc b/media/gpu/vaapi/vaapi_picture_native_pixmap_ozone.cc
new file mode 100644
index 0000000..e961501
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_picture_native_pixmap_ozone.cc
@@ -0,0 +1,159 @@
+// Copyright 2014 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "media/gpu/vaapi/vaapi_picture_native_pixmap_ozone.h"
+
+#include "gpu/command_buffer/service/shared_image/gl_image_native_pixmap.h"
+#include "media/base/format_utils.h"
+#include "media/gpu/buffer_validation.h"
+#include "media/gpu/chromeos/platform_video_frame_utils.h"
+#include "media/gpu/macros.h"
+#include "media/gpu/vaapi/va_surface.h"
+#include "media/gpu/vaapi/vaapi_status.h"
+#include "media/gpu/vaapi/vaapi_wrapper.h"
+#include "ui/gfx/gpu_memory_buffer.h"
+#include "ui/gfx/linux/native_pixmap_dmabuf.h"
+#include "ui/gfx/native_pixmap.h"
+#include "ui/gl/gl_bindings.h"
+#include "ui/ozone/public/ozone_platform.h"
+#include "ui/ozone/public/surface_factory_ozone.h"
+
+namespace media {
+
+VaapiPictureNativePixmapOzone::VaapiPictureNativePixmapOzone(
+    scoped_refptr<VaapiWrapper> vaapi_wrapper,
+    const MakeGLContextCurrentCallback& make_context_current_cb,
+    const BindGLImageCallback& bind_image_cb,
+    int32_t picture_buffer_id,
+    const gfx::Size& size,
+    const gfx::Size& visible_size,
+    uint32_t texture_id,
+    uint32_t client_texture_id,
+    uint32_t texture_target)
+    : VaapiPictureNativePixmap(std::move(vaapi_wrapper),
+                               make_context_current_cb,
+                               bind_image_cb,
+                               picture_buffer_id,
+                               size,
+                               visible_size,
+                               texture_id,
+                               client_texture_id,
+                               texture_target) {
+  DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
+  // Either |texture_id| and |client_texture_id| are both zero, or not.
+  DCHECK((texture_id == 0 && client_texture_id == 0) ||
+         (texture_id != 0 && client_texture_id != 0));
+}
+
+VaapiPictureNativePixmapOzone::~VaapiPictureNativePixmapOzone() {
+  DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
+  if (gl_image_ && make_context_current_cb_.Run()) {
+    DCHECK_EQ(glGetError(), static_cast<GLenum>(GL_NO_ERROR));
+  }
+
+  // Reset |va_surface_| before |gl_image_| to preserve the order of destruction
+  // before the refactoring done in
+  // https://chromium-review.googlesource.com/c/chromium/src/+/4025005.
+  // TODO(crbug.com/1366367): Determine whether preserving this order matters
+  // and remove these calls if not.
+  va_surface_.reset();
+  gl_image_.reset();
+}
+
+VaapiStatus VaapiPictureNativePixmapOzone::Initialize(
+    scoped_refptr<gfx::NativePixmap> pixmap) {
+  DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
+  DCHECK(pixmap);
+  DCHECK(pixmap->AreDmaBufFdsValid());
+  // Create a |va_surface_| from dmabuf fds (pixmap->GetDmaBufFd)
+  va_surface_ = vaapi_wrapper_->CreateVASurfaceForPixmap(pixmap);
+  if (!va_surface_) {
+    LOG(ERROR) << "Failed creating VASurface for NativePixmap";
+    return VaapiStatus::Codes::kNoSurface;
+  }
+
+  // ARC++ has no texture ids.
+  if (texture_id_ == 0 && client_texture_id_ == 0)
+    return VaapiStatus::Codes::kOk;
+
+  // Import dmabuf fds into the output gl texture through EGLImage.
+  if (make_context_current_cb_ && !make_context_current_cb_.Run())
+    return VaapiStatus::Codes::kBadContext;
+
+  const gfx::BufferFormat format = pixmap->GetBufferFormat();
+
+  // TODO(b/220336463): plumb the right color space.
+  auto image = gpu::GLImageNativePixmap::Create(
+      visible_size_, format, std::move(pixmap),
+      base::strict_cast<GLenum>(texture_target_),
+      base::strict_cast<GLuint>(texture_id_));
+  if (!image) {
+    LOG(ERROR) << "Failed to create GLImage";
+    return VaapiStatus::Codes::kFailedToInitializeImage;
+  }
+
+  gl_image_ = std::move(image);
+
+  if (bind_image_cb_ &&
+      !bind_image_cb_.Run(client_texture_id_, texture_target_, gl_image_)) {
+    LOG(ERROR) << "Failed to bind client_texture_id";
+    return VaapiStatus::Codes::kFailedToBindImage;
+  }
+
+  return VaapiStatus::Codes::kOk;
+}
+
+VaapiStatus VaapiPictureNativePixmapOzone::Allocate(gfx::BufferFormat format) {
+  DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
+
+  ui::OzonePlatform* platform = ui::OzonePlatform::GetInstance();
+  ui::SurfaceFactoryOzone* factory = platform->GetSurfaceFactoryOzone();
+  gfx::BufferUsage buffer_usage = gfx::BufferUsage::SCANOUT_VDA_WRITE;
+#if BUILDFLAG(USE_VAAPI_X11)
+  // The 'VaapiVideoDecodeAccelerator' requires the VPP to download the decoded
+  // frame from the internal surface to the allocated native pixmap.
+  // 'SCANOUT_VDA_WRITE' is used for 'YUV_420_BIPLANAR' on ChromeOS; For Linux,
+  // the usage is set to 'GPU_READ' for 'RGBX_8888'.
+  DCHECK(format == gfx::BufferFormat::RGBX_8888);
+  buffer_usage = gfx::BufferUsage::GPU_READ;
+#endif
+  auto pixmap = factory->CreateNativePixmap(
+      gfx::kNullAcceleratedWidget, nullptr, size_, format, buffer_usage,
+      /*framebuffer_size=*/visible_size_);
+  if (!pixmap) {
+    return VaapiStatus::Codes::kNoPixmap;
+  }
+
+  return Initialize(std::move(pixmap));
+}
+
+bool VaapiPictureNativePixmapOzone::ImportGpuMemoryBufferHandle(
+    gfx::BufferFormat format,
+    gfx::GpuMemoryBufferHandle gpu_memory_buffer_handle) {
+  DCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);
+
+  if (!CanImportGpuMemoryBufferHandle(size_, format,
+                                      gpu_memory_buffer_handle)) {
+    VLOGF(1) << "Can't import the given GpuMemoryBufferHandle";
+    return false;
+  }
+
+  const auto& plane = gpu_memory_buffer_handle.native_pixmap_handle.planes[0];
+  if (size_.width() > static_cast<int>(plane.stride) ||
+      size_.GetArea() > static_cast<int>(plane.size)) {
+    DLOG(ERROR) << "GpuMemoryBufferHandle (stride=" << plane.stride
+                << ", size=" << plane.size
+                << "is smaller than size_=" << size_.ToString();
+    return false;
+  }
+
+  // gfx::NativePixmapDmaBuf() will take ownership of the handle.
+  return Initialize(
+             base::MakeRefCounted<gfx::NativePixmapDmaBuf>(
+                 size_, format,
+                 std::move(gpu_memory_buffer_handle.native_pixmap_handle)))
+      .is_ok();
+}
+
+}  // namespace media
diff --git a/media/gpu/vaapi/vaapi_picture_native_pixmap_ozone.h b/media/gpu/vaapi/vaapi_picture_native_pixmap_ozone.h
new file mode 100644
index 0000000..eaced9a
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_picture_native_pixmap_ozone.h
@@ -0,0 +1,63 @@
+// Copyright 2014 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef MEDIA_GPU_VAAPI_VAAPI_PICTURE_NATIVE_PIXMAP_OZONE_H_
+#define MEDIA_GPU_VAAPI_VAAPI_PICTURE_NATIVE_PIXMAP_OZONE_H_
+
+#include <stdint.h>
+
+#include "base/memory/scoped_refptr.h"
+#include "base/memory/weak_ptr.h"
+#include "media/gpu/vaapi/vaapi_picture_native_pixmap.h"
+#include "ui/gfx/buffer_types.h"
+#include "ui/gfx/geometry/size.h"
+
+namespace gfx {
+class NativePixmap;
+}  // namespace gfx
+
+namespace gpu {
+class GLImageNativePixmap;
+}
+
+namespace media {
+
+class VaapiWrapper;
+
+// Implementation of VaapiPictureNativePixmap using Ozone.
+class VaapiPictureNativePixmapOzone : public VaapiPictureNativePixmap {
+ public:
+  VaapiPictureNativePixmapOzone(
+      scoped_refptr<VaapiWrapper> vaapi_wrapper,
+      const MakeGLContextCurrentCallback& make_context_current_cb,
+      const BindGLImageCallback& bind_image_cb_,
+      int32_t picture_buffer_id,
+      const gfx::Size& size,
+      const gfx::Size& visible_size,
+      uint32_t texture_id,
+      uint32_t client_texture_id,
+      uint32_t texture_target);
+
+  VaapiPictureNativePixmapOzone(const VaapiPictureNativePixmapOzone&) = delete;
+  VaapiPictureNativePixmapOzone& operator=(
+      const VaapiPictureNativePixmapOzone&) = delete;
+
+  ~VaapiPictureNativePixmapOzone() override;
+
+  // VaapiPicture implementation.
+  VaapiStatus Allocate(gfx::BufferFormat format) override;
+  bool ImportGpuMemoryBufferHandle(
+      gfx::BufferFormat format,
+      gfx::GpuMemoryBufferHandle gpu_memory_buffer_handle) override;
+
+ private:
+  VaapiStatus Initialize(scoped_refptr<gfx::NativePixmap> pixmap);
+
+  // GLImage bound to the GL textures used by the VDA client.
+  scoped_refptr<gpu::GLImageNativePixmap> gl_image_;
+};
+
+}  // namespace media
+
+#endif  // MEDIA_GPU_VAAPI_VAAPI_PICTURE_NATIVE_PIXMAP_OZONE_H_
diff --git a/media/gpu/vaapi/vaapi_video_decode_accelerator.cc b/media/gpu/vaapi/vaapi_video_decode_accelerator.cc
new file mode 100644
index 0000000..9b3ffa9
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_video_decode_accelerator.cc
@@ -0,0 +1,1313 @@
+// Copyright 2012 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "media/gpu/vaapi/vaapi_video_decode_accelerator.h"
+
+#include <string.h>
+#include <va/va.h>
+
+#include <memory>
+
+#include "base/containers/contains.h"
+#include "base/containers/cxx20_erase.h"
+#include "base/cpu.h"
+#include "base/files/scoped_file.h"
+#include "base/functional/bind.h"
+#include "base/functional/callback_helpers.h"
+#include "base/json/json_writer.h"
+#include "base/logging.h"
+#include "base/metrics/histogram_macros.h"
+#include "base/numerics/safe_conversions.h"
+#include "base/strings/string_util.h"
+#include "base/strings/stringprintf.h"
+#include "base/synchronization/waitable_event.h"
+#include "base/task/bind_post_task.h"
+#include "base/task/single_thread_task_runner.h"
+#include "base/trace_event/memory_dump_manager.h"
+#include "base/trace_event/process_memory_dump.h"
+#include "base/trace_event/trace_event.h"
+#include "build/build_config.h"
+#include "gpu/ipc/service/gpu_channel.h"
+#include "media/base/format_utils.h"
+#include "media/base/media_log.h"
+#include "media/base/video_util.h"
+#include "media/gpu/accelerated_video_decoder.h"
+#include "media/gpu/h264_decoder.h"
+#include "media/gpu/macros.h"
+#include "media/gpu/vaapi/h264_vaapi_video_decoder_delegate.h"
+#include "media/gpu/vaapi/vaapi_common.h"
+#include "media/gpu/vaapi/vaapi_picture.h"
+#include "media/gpu/vaapi/vaapi_utils.h"
+#include "media/gpu/vaapi/vp8_vaapi_video_decoder_delegate.h"
+#include "media/gpu/vaapi/vp9_vaapi_video_decoder_delegate.h"
+#include "media/gpu/vp8_decoder.h"
+#include "media/gpu/vp9_decoder.h"
+#include "media/video/picture.h"
+
+namespace media {
+
+namespace {
+
+// Returns the preferred VA_RT_FORMAT for the given |profile|.
+unsigned int GetVaFormatForVideoCodecProfile(VideoCodecProfile profile) {
+  if (profile == VP9PROFILE_PROFILE2 || profile == VP9PROFILE_PROFILE3)
+    return VA_RT_FORMAT_YUV420_10BPP;
+  return VA_RT_FORMAT_YUV420;
+}
+
+// Returns true if the CPU is an Intel Gemini Lake or later (including Kaby
+// Lake) Cpu platform id's are referenced from the following file in kernel
+// source arch/x86/include/asm/intel-family.h
+bool IsGeminiLakeOrLater() {
+  constexpr int kPentiumAndLaterFamily = 0x06;
+  constexpr int kGeminiLakeModelId = 0x7A;
+  static base::CPU cpuid;
+  static bool is_geminilake_or_later =
+      cpuid.family() == kPentiumAndLaterFamily &&
+      cpuid.model() >= kGeminiLakeModelId;
+  return is_geminilake_or_later;
+}
+
+}  // namespace
+
+#define RETURN_AND_NOTIFY_ON_FAILURE(result, log, error_code, ret) \
+  do {                                                             \
+    if (!(result)) {                                               \
+      LOG(ERROR) << log;                                           \
+      NotifyError(error_code);                                     \
+      return ret;                                                  \
+    }                                                              \
+  } while (0)
+
+#define RETURN_AND_NOTIFY_ON_STATUS(status, ret) \
+  do {                                           \
+    if (!status.is_ok()) {                       \
+      NotifyStatus(status);                      \
+      return ret;                                \
+    }                                            \
+  } while (0)
+
+class VaapiVideoDecodeAccelerator::InputBuffer {
+ public:
+  InputBuffer() : buffer_(nullptr) {}
+  InputBuffer(int32_t id,
+              scoped_refptr<DecoderBuffer> buffer,
+              base::OnceCallback<void(int32_t id)> release_cb)
+      : id_(id),
+        buffer_(std::move(buffer)),
+        release_cb_(std::move(release_cb)) {}
+
+  InputBuffer(const InputBuffer&) = delete;
+  InputBuffer& operator=(const InputBuffer&) = delete;
+
+  ~InputBuffer() {
+    DVLOGF(4) << "id = " << id_;
+    if (release_cb_)
+      std::move(release_cb_).Run(id_);
+  }
+
+  // Indicates this is a dummy buffer for flush request.
+  bool IsFlushRequest() const { return !buffer_; }
+  int32_t id() const { return id_; }
+  const scoped_refptr<DecoderBuffer>& buffer() const { return buffer_; }
+
+ private:
+  const int32_t id_ = -1;
+  const scoped_refptr<DecoderBuffer> buffer_;
+  base::OnceCallback<void(int32_t id)> release_cb_;
+};
+
+void VaapiVideoDecodeAccelerator::NotifyStatus(VaapiStatus status) {
+  DCHECK(!status.is_ok());
+  // Send a platform notification error
+  NotifyError(PLATFORM_FAILURE);
+
+  // TODO(crbug.com/1103510) there is no MediaLog here, we should change that.
+  std::string output_str;
+  base::JSONWriter::Write(MediaSerialize(status), &output_str);
+  DLOG(ERROR) << output_str;
+}
+
+void VaapiVideoDecodeAccelerator::NotifyError(Error error) {
+  if (!task_runner_->BelongsToCurrentThread()) {
+    DCHECK(decoder_thread_task_runner_->BelongsToCurrentThread());
+    task_runner_->PostTask(
+        FROM_HERE, base::BindOnce(&VaapiVideoDecodeAccelerator::NotifyError,
+                                  weak_this_, error));
+    return;
+  }
+
+  VLOGF(1) << "Notifying of error " << error;
+  if (client_) {
+    client_->NotifyError(error);
+    client_ptr_factory_.reset();
+  }
+}
+
+VaapiVideoDecodeAccelerator::VaapiVideoDecodeAccelerator(
+    const MakeGLContextCurrentCallback& make_context_current_cb,
+    const BindGLImageCallback& bind_image_cb)
+    : state_(kUninitialized),
+      input_ready_(&lock_),
+      buffer_allocation_mode_(BufferAllocationMode::kNormal),
+      surfaces_available_(&lock_),
+      va_surface_format_(VA_INVALID_ID),
+      task_runner_(base::SingleThreadTaskRunner::GetCurrentDefault()),
+      decoder_thread_("VaapiDecoderThread"),
+      finish_flush_pending_(false),
+      awaiting_va_surfaces_recycle_(false),
+      requested_num_pics_(0),
+      requested_num_reference_frames_(0),
+      previously_requested_num_reference_frames_(0),
+      profile_(VIDEO_CODEC_PROFILE_UNKNOWN),
+      make_context_current_cb_(make_context_current_cb),
+      bind_image_cb_(bind_image_cb),
+      weak_this_factory_(this) {
+  weak_this_ = weak_this_factory_.GetWeakPtr();
+  va_surface_recycle_cb_ =
+      base::BindPostTaskToCurrentDefault(base::BindRepeating(
+          &VaapiVideoDecodeAccelerator::RecycleVASurface, weak_this_));
+  base::trace_event::MemoryDumpManager::GetInstance()->RegisterDumpProvider(
+      this, "media::VaapiVideoDecodeAccelerator",
+      base::SingleThreadTaskRunner::GetCurrentDefault());
+}
+
+VaapiVideoDecodeAccelerator::~VaapiVideoDecodeAccelerator() {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+  base::trace_event::MemoryDumpManager::GetInstance()->UnregisterDumpProvider(
+      this);
+}
+
+bool VaapiVideoDecodeAccelerator::Initialize(const Config& config,
+                                             Client* client) {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+
+  vaapi_picture_factory_ = std::make_unique<VaapiPictureFactory>();
+
+  if (config.is_encrypted()) {
+    NOTREACHED() << "Encrypted streams are not supported for this VDA";
+    return false;
+  }
+
+  client_ptr_factory_.reset(new base::WeakPtrFactory<Client>(client));
+  client_ = client_ptr_factory_->GetWeakPtr();
+
+  VideoCodecProfile profile = config.profile;
+
+  base::AutoLock auto_lock(lock_);
+  DCHECK_EQ(state_, kUninitialized);
+  VLOGF(2) << "Initializing VAVDA, profile: " << GetProfileName(profile);
+
+  vaapi_wrapper_ = VaapiWrapper::CreateForVideoCodec(
+      VaapiWrapper::kDecode, profile, EncryptionScheme::kUnencrypted,
+      base::BindRepeating(&ReportVaapiErrorToUMA,
+                          "Media.VaapiVideoDecodeAccelerator.VAAPIError"),
+      /*enforce_sequence_affinity=*/false);
+
+  UMA_HISTOGRAM_BOOLEAN("Media.VAVDA.VaapiWrapperCreationSuccess",
+                        vaapi_wrapper_.get());
+  if (!vaapi_wrapper_.get()) {
+    VLOGF(1) << "Failed initializing VAAPI for profile "
+             << GetProfileName(profile);
+    return false;
+  }
+
+  if (profile >= H264PROFILE_MIN && profile <= H264PROFILE_MAX) {
+    auto accelerator =
+        std::make_unique<H264VaapiVideoDecoderDelegate>(this, vaapi_wrapper_);
+    decoder_delegate_ = accelerator.get();
+    decoder_.reset(new H264Decoder(std::move(accelerator), profile,
+                                   config.container_color_space));
+  } else if (profile >= VP8PROFILE_MIN && profile <= VP8PROFILE_MAX) {
+    auto accelerator =
+        std::make_unique<VP8VaapiVideoDecoderDelegate>(this, vaapi_wrapper_);
+    decoder_delegate_ = accelerator.get();
+    decoder_.reset(new VP8Decoder(std::move(accelerator)));
+  } else if (profile >= VP9PROFILE_MIN && profile <= VP9PROFILE_MAX) {
+    auto accelerator =
+        std::make_unique<VP9VaapiVideoDecoderDelegate>(this, vaapi_wrapper_);
+    decoder_delegate_ = accelerator.get();
+    decoder_.reset(new VP9Decoder(std::move(accelerator), profile,
+                                  config.container_color_space));
+  } else {
+    VLOGF(1) << "Unsupported profile " << GetProfileName(profile);
+    return false;
+  }
+
+  CHECK(decoder_thread_.Start());
+  decoder_thread_task_runner_ = decoder_thread_.task_runner();
+
+  state_ = kIdle;
+  profile_ = profile;
+  output_mode_ = config.output_mode;
+  buffer_allocation_mode_ = DecideBufferAllocationMode();
+  previously_requested_num_reference_frames_ = 0;
+  return true;
+}
+
+void VaapiVideoDecodeAccelerator::OutputPicture(
+    scoped_refptr<VASurface> va_surface,
+    int32_t input_id,
+    gfx::Rect visible_rect,
+    const VideoColorSpace& picture_color_space) {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+
+  const VASurfaceID va_surface_id = va_surface->id();
+
+  VaapiPicture* picture = nullptr;
+  {
+    base::AutoLock auto_lock(lock_);
+    int32_t picture_buffer_id = available_picture_buffers_.front();
+    if (buffer_allocation_mode_ == BufferAllocationMode::kNone) {
+      // Find the |pictures_| entry matching |va_surface_id|.
+      for (const auto& id_and_picture : pictures_) {
+        if (id_and_picture.second->va_surface_id() == va_surface_id) {
+          picture_buffer_id = id_and_picture.first;
+          break;
+        }
+      }
+    }
+    picture = pictures_[picture_buffer_id].get();
+    DCHECK(base::Contains(available_picture_buffers_, picture_buffer_id));
+    base::Erase(available_picture_buffers_, picture_buffer_id);
+  }
+
+  DCHECK(picture) << " could not find " << va_surface_id << " available";
+  const int32_t output_id = picture->picture_buffer_id();
+
+  DVLOGF(4) << "Outputting VASurface " << va_surface->id()
+            << " into pixmap bound to picture buffer id " << output_id;
+
+  if (buffer_allocation_mode_ != BufferAllocationMode::kNone) {
+    TRACE_EVENT2("media,gpu", "VAVDA::DownloadFromSurface", "input_id",
+                 input_id, "output_id", output_id);
+    RETURN_AND_NOTIFY_ON_FAILURE(picture->DownloadFromSurface(va_surface),
+                                 "Failed putting surface into pixmap",
+                                 PLATFORM_FAILURE, );
+  }
+
+  {
+    base::AutoLock auto_lock(lock_);
+    TRACE_COUNTER_ID2("media,gpu", "Vaapi frames at client", this, "used",
+                      pictures_.size() - available_picture_buffers_.size(),
+                      "available", available_picture_buffers_.size());
+  }
+
+  DVLOGF(4) << "Notifying output picture id " << output_id << " for input "
+            << input_id
+            << " is ready. visible rect: " << visible_rect.ToString();
+  if (!client_)
+    return;
+
+  Picture client_picture(output_id, input_id, visible_rect,
+                         picture_color_space.ToGfxColorSpace(),
+                         picture->AllowOverlay());
+  client_picture.set_read_lock_fences_enabled(true);
+  // Notify the |client_| a picture is ready to be consumed.
+  client_->PictureReady(client_picture);
+}
+
+void VaapiVideoDecodeAccelerator::TryOutputPicture() {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+
+  // Handle Destroy() arriving while pictures are queued for output.
+  if (!client_)
+    return;
+
+  {
+    base::AutoLock auto_lock(lock_);
+    if (pending_output_cbs_.empty() || available_picture_buffers_.empty())
+      return;
+  }
+
+  auto output_cb = std::move(pending_output_cbs_.front());
+  pending_output_cbs_.pop();
+  std::move(output_cb).Run();
+
+  if (finish_flush_pending_ && pending_output_cbs_.empty())
+    FinishFlush();
+}
+
+void VaapiVideoDecodeAccelerator::QueueInputBuffer(
+    scoped_refptr<DecoderBuffer> buffer,
+    int32_t bitstream_id) {
+  DVLOGF(4) << "Queueing new input buffer id: " << bitstream_id
+            << " size: " << (buffer->end_of_stream() ? 0 : buffer->data_size());
+  DCHECK(task_runner_->BelongsToCurrentThread());
+  TRACE_EVENT1("media,gpu", "QueueInputBuffer", "input_id", bitstream_id);
+
+  base::AutoLock auto_lock(lock_);
+  if (buffer->end_of_stream()) {
+    auto flush_buffer = std::make_unique<InputBuffer>();
+    DCHECK(flush_buffer->IsFlushRequest());
+    input_buffers_.push(std::move(flush_buffer));
+  } else {
+    auto input_buffer = std::make_unique<InputBuffer>(
+        bitstream_id, std::move(buffer),
+        base::BindPostTaskToCurrentDefault(
+            base::BindOnce(&Client::NotifyEndOfBitstreamBuffer, client_)));
+    input_buffers_.push(std::move(input_buffer));
+  }
+
+  TRACE_COUNTER1("media,gpu", "Vaapi input buffers", input_buffers_.size());
+  input_ready_.Signal();
+
+  switch (state_) {
+    case kIdle:
+      state_ = kDecoding;
+      decoder_thread_task_runner_->PostTask(
+          FROM_HERE, base::BindOnce(&VaapiVideoDecodeAccelerator::DecodeTask,
+                                    base::Unretained(this)));
+      break;
+
+    case kDecoding:
+      // Decoder already running.
+      break;
+
+    case kResetting:
+      // When resetting, allow accumulating bitstream buffers, so that
+      // the client can queue after-seek-buffers while we are finishing with
+      // the before-seek one.
+      break;
+
+    default:
+      LOG(ERROR) << "Decode/Flush request from client in invalid state: "
+                 << state_;
+      NotifyError(PLATFORM_FAILURE);
+      break;
+  }
+}
+
+bool VaapiVideoDecodeAccelerator::GetCurrInputBuffer_Locked() {
+  DCHECK(decoder_thread_task_runner_->BelongsToCurrentThread());
+  lock_.AssertAcquired();
+
+  if (curr_input_buffer_.get())
+    return true;
+
+  // Will only wait if it is expected that in current state new buffers will
+  // be queued from the client via Decode(). The state can change during wait.
+  while (input_buffers_.empty() && (state_ == kDecoding || state_ == kIdle))
+    input_ready_.Wait();
+
+  // We could have got woken up in a different state or never got to sleep
+  // due to current state.
+  if (state_ != kDecoding && state_ != kIdle)
+    return false;
+
+  DCHECK(!input_buffers_.empty());
+  curr_input_buffer_ = std::move(input_buffers_.front());
+  input_buffers_.pop();
+  TRACE_COUNTER1("media,gpu", "Vaapi input buffers", input_buffers_.size());
+
+  if (curr_input_buffer_->IsFlushRequest()) {
+    DVLOGF(4) << "New flush buffer";
+    return true;
+  }
+
+  DVLOGF(4) << "New |curr_input_buffer_|, id: " << curr_input_buffer_->id()
+            << " size: " << curr_input_buffer_->buffer()->data_size() << "B";
+  decoder_->SetStream(curr_input_buffer_->id(), *curr_input_buffer_->buffer());
+  return true;
+}
+
+void VaapiVideoDecodeAccelerator::ReturnCurrInputBuffer_Locked() {
+  DCHECK(decoder_thread_task_runner_->BelongsToCurrentThread());
+  lock_.AssertAcquired();
+  DCHECK(curr_input_buffer_.get());
+  curr_input_buffer_.reset();
+}
+
+// TODO(posciak): refactor the whole class to remove sleeping in wait for
+// surfaces, and reschedule DecodeTask instead.
+bool VaapiVideoDecodeAccelerator::WaitForSurfaces_Locked() {
+  DCHECK(decoder_thread_task_runner_->BelongsToCurrentThread());
+  lock_.AssertAcquired();
+
+  while (available_va_surfaces_.empty() &&
+         (state_ == kDecoding || state_ == kIdle)) {
+    surfaces_available_.Wait();
+  }
+
+  return state_ == kDecoding || state_ == kIdle;
+}
+
+void VaapiVideoDecodeAccelerator::DecodeTask() {
+  DCHECK(decoder_thread_task_runner_->BelongsToCurrentThread());
+  base::AutoLock auto_lock(lock_);
+
+  if (state_ != kDecoding)
+    return;
+  DVLOGF(4) << "Decode task";
+
+  // Try to decode what stream data is (still) in the decoder until we run out
+  // of it.
+  while (GetCurrInputBuffer_Locked()) {
+    DCHECK(curr_input_buffer_.get());
+
+    if (curr_input_buffer_->IsFlushRequest()) {
+      FlushTask();
+      break;
+    }
+
+    AcceleratedVideoDecoder::DecodeResult res;
+    {
+      // We are OK releasing the lock here, as decoder never calls our methods
+      // directly and we will reacquire the lock before looking at state again.
+      // This is the main decode function of the decoder and while keeping
+      // the lock for its duration would be fine, it would defeat the purpose
+      // of having a separate decoder thread.
+      base::AutoUnlock auto_unlock(lock_);
+      TRACE_EVENT0("media,gpu", "VAVDA::Decode");
+      res = decoder_->Decode();
+    }
+
+    switch (res) {
+      case AcceleratedVideoDecoder::kConfigChange: {
+        const uint8_t bit_depth = decoder_->GetBitDepth();
+        RETURN_AND_NOTIFY_ON_FAILURE(
+            bit_depth == 8u,
+            "Unsupported bit depth: " << base::strict_cast<int>(bit_depth),
+            PLATFORM_FAILURE, );
+        // The visible rect should be a subset of the picture size. Otherwise,
+        // the encoded stream is bad.
+        const gfx::Size pic_size = decoder_->GetPicSize();
+        const gfx::Rect visible_rect = decoder_->GetVisibleRect();
+        RETURN_AND_NOTIFY_ON_FAILURE(
+            gfx::Rect(pic_size).Contains(visible_rect),
+            "The visible rectangle is not contained by the picture size",
+            UNREADABLE_INPUT, );
+        VLOGF(2) << "Decoder requesting a new set of surfaces";
+        size_t required_num_of_pictures = decoder_->GetRequiredNumOfPictures();
+        if (buffer_allocation_mode_ == BufferAllocationMode::kNone &&
+            profile_ >= H264PROFILE_MIN && profile_ <= H264PROFILE_MAX) {
+          // For H.264, the decoder might request too few pictures. In
+          // BufferAllocationMode::kNone, this can cause us to do a lot of busy
+          // work waiting for picture buffers to come back from the client (see
+          // crbug.com/910986#c32). This is a workaround to increase the
+          // likelihood that we don't have to wait on buffers to come back from
+          // the client. |kNumOfPics| is picked to mirror the value returned by
+          // VP9Decoder::GetRequiredNumOfPictures().
+          constexpr size_t kMinNumOfPics = 13u;
+          required_num_of_pictures =
+              std::max(kMinNumOfPics, required_num_of_pictures);
+        }
+
+        // Notify |decoder_delegate_| of an imminent VAContextID destruction, so
+        // it can destroy any internal structures making use of it.
+        decoder_delegate_->OnVAContextDestructionSoon();
+
+        task_runner_->PostTask(
+            FROM_HERE,
+            base::BindOnce(
+                &VaapiVideoDecodeAccelerator::InitiateSurfaceSetChange,
+                weak_this_, required_num_of_pictures, pic_size,
+                decoder_->GetNumReferenceFrames(), visible_rect));
+        // We'll get rescheduled once ProvidePictureBuffers() finishes.
+        return;
+      }
+
+      case AcceleratedVideoDecoder::kColorSpaceChange:
+        NOTIMPLEMENTED_LOG_ONCE();
+        break;
+
+      case AcceleratedVideoDecoder::kRanOutOfStreamData:
+        ReturnCurrInputBuffer_Locked();
+        break;
+
+      case AcceleratedVideoDecoder::kRanOutOfSurfaces:
+        // No more output buffers in the decoder, try getting more or go to
+        // sleep waiting for them.
+        if (!WaitForSurfaces_Locked())
+          return;
+
+        break;
+
+      case AcceleratedVideoDecoder::kNeedContextUpdate:
+        // This should not happen as we return false from
+        // NeedsCompressedHeaderParsed().
+        NOTREACHED() << "Context updates not supported";
+        return;
+
+      case AcceleratedVideoDecoder::kDecodeError:
+        RETURN_AND_NOTIFY_ON_FAILURE(false, "Error decoding stream",
+                                     PLATFORM_FAILURE, );
+        return;
+
+      case AcceleratedVideoDecoder::kTryAgain:
+        NOTREACHED() << "Should not reach here unless this class accepts "
+                        "encrypted streams.";
+        RETURN_AND_NOTIFY_ON_FAILURE(false, "Error decoding stream",
+                                     PLATFORM_FAILURE, );
+        return;
+    }
+  }
+}
+
+void VaapiVideoDecodeAccelerator::InitiateSurfaceSetChange(
+    size_t num_pics,
+    gfx::Size size,
+    size_t num_reference_frames,
+    const gfx::Rect& visible_rect) {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+  DCHECK(!awaiting_va_surfaces_recycle_);
+  DCHECK_GT(num_pics, num_reference_frames);
+
+  // At this point decoder has stopped running and has already posted onto our
+  // loop any remaining output request callbacks, which executed before we got
+  // here. Some of them might have been pended though, because we might not have
+  // had enough PictureBuffers to output surfaces to. Initiate a wait cycle,
+  // which will wait for client to return enough PictureBuffers to us, so that
+  // we can finish all pending output callbacks, releasing associated surfaces.
+  awaiting_va_surfaces_recycle_ = true;
+
+  requested_pic_size_ = size;
+  requested_visible_rect_ = visible_rect;
+  if (buffer_allocation_mode_ == BufferAllocationMode::kSuperReduced) {
+    // Add one to the reference frames for the one being currently egressed.
+    requested_num_reference_frames_ = num_reference_frames + 1;
+    requested_num_pics_ = num_pics - num_reference_frames;
+  } else if (buffer_allocation_mode_ == BufferAllocationMode::kReduced) {
+    // Add one to the reference frames for the one being currently egressed,
+    // and an extra allocation for both |client_| and |decoder_|.
+    requested_num_reference_frames_ = num_reference_frames + 2;
+    requested_num_pics_ = num_pics - num_reference_frames + 1;
+  } else {
+    requested_num_reference_frames_ = 0;
+    requested_num_pics_ = num_pics + num_extra_pics_;
+  }
+
+  VLOGF(2) << " |requested_num_pics_| = " << requested_num_pics_
+           << "; |requested_num_reference_frames_| = "
+           << requested_num_reference_frames_;
+
+  TryFinishSurfaceSetChange();
+}
+
+void VaapiVideoDecodeAccelerator::TryFinishSurfaceSetChange() {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+
+  if (!awaiting_va_surfaces_recycle_)
+    return;
+
+  base::AutoLock auto_lock(lock_);
+  const size_t expected_max_available_va_surfaces =
+      IsBufferAllocationModeReducedOrSuperReduced()
+          ? previously_requested_num_reference_frames_
+          : pictures_.size();
+  if (!pending_output_cbs_.empty() ||
+      expected_max_available_va_surfaces != available_va_surfaces_.size()) {
+    // If we're here the stream resolution has changed; we need to wait until:
+    // - all |pending_output_cbs_| have been executed
+    // - all VASurfaces are back to |available_va_surfaces_|; we can't use
+    //   |requested_num_reference_frames_| for comparison, since it might have
+    //   changed in the previous call to InitiateSurfaceSetChange(), so we use
+    //   |previously_requested_num_reference_frames_| instead.
+    DVLOGF(2) << "Awaiting pending output/surface release callbacks to finish";
+    task_runner_->PostTask(
+        FROM_HERE,
+        base::BindOnce(&VaapiVideoDecodeAccelerator::TryFinishSurfaceSetChange,
+                       weak_this_));
+    return;
+  }
+
+  previously_requested_num_reference_frames_ = requested_num_reference_frames_;
+
+  // All surfaces released, destroy them and dismiss all PictureBuffers.
+  awaiting_va_surfaces_recycle_ = false;
+
+  const VideoCodecProfile new_profile = decoder_->GetProfile();
+  if (profile_ != new_profile) {
+    profile_ = new_profile;
+    auto new_vaapi_wrapper = VaapiWrapper::CreateForVideoCodec(
+        VaapiWrapper::kDecode, profile_, EncryptionScheme::kUnencrypted,
+        base::BindRepeating(&ReportVaapiErrorToUMA,
+                            "Media.VaapiVideoDecodeAccelerator.VAAPIError"),
+        /*enforce_sequence_affinity=*/false);
+    RETURN_AND_NOTIFY_ON_FAILURE(new_vaapi_wrapper.get(),
+                                 "Failed creating VaapiWrapper",
+                                 INVALID_ARGUMENT, );
+    decoder_delegate_->set_vaapi_wrapper(new_vaapi_wrapper.get());
+    vaapi_wrapper_ = std::move(new_vaapi_wrapper);
+  } else {
+    vaapi_wrapper_->DestroyContext();
+  }
+
+  available_va_surfaces_.clear();
+
+  for (auto iter = pictures_.begin(); iter != pictures_.end(); ++iter) {
+    VLOGF(2) << "Dismissing picture id: " << iter->first;
+    if (client_)
+      client_->DismissPictureBuffer(iter->first);
+  }
+  pictures_.clear();
+
+  // And ask for a new set as requested.
+  VLOGF(2) << "Requesting " << requested_num_pics_
+           << " pictures of size: " << requested_pic_size_.ToString()
+           << " and visible rectangle = " << requested_visible_rect_.ToString();
+
+  const absl::optional<VideoPixelFormat> format =
+      GfxBufferFormatToVideoPixelFormat(
+          vaapi_picture_factory_->GetBufferFormat());
+  CHECK(format);
+  task_runner_->PostTask(
+      FROM_HERE, base::BindOnce(&Client::ProvidePictureBuffersWithVisibleRect,
+                                client_, requested_num_pics_, *format, 1,
+                                requested_pic_size_, requested_visible_rect_,
+                                vaapi_picture_factory_->GetGLTextureTarget()));
+  // |client_| may respond via AssignPictureBuffers().
+}
+
+void VaapiVideoDecodeAccelerator::Decode(BitstreamBuffer bitstream_buffer) {
+  Decode(bitstream_buffer.ToDecoderBuffer(), bitstream_buffer.id());
+}
+
+void VaapiVideoDecodeAccelerator::Decode(scoped_refptr<DecoderBuffer> buffer,
+                                         int32_t bitstream_id) {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+  TRACE_EVENT1("media,gpu", "VAVDA::Decode", "Buffer id", bitstream_id);
+
+  if (bitstream_id < 0) {
+    LOG(ERROR) << "Invalid bitstream_buffer, id: " << bitstream_id;
+    NotifyError(INVALID_ARGUMENT);
+    return;
+  }
+
+  if (!buffer) {
+    if (client_)
+      client_->NotifyEndOfBitstreamBuffer(bitstream_id);
+    return;
+  }
+
+  QueueInputBuffer(std::move(buffer), bitstream_id);
+}
+
+void VaapiVideoDecodeAccelerator::AssignPictureBuffers(
+    const std::vector<PictureBuffer>& buffers) {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+  base::AutoLock auto_lock(lock_);
+  DCHECK(pictures_.empty());
+
+  available_picture_buffers_.clear();
+
+  RETURN_AND_NOTIFY_ON_FAILURE(
+      buffers.size() >= requested_num_pics_,
+      "Got an invalid number of picture buffers. (Got " << buffers.size()
+      << ", requested " << requested_num_pics_ << ")", INVALID_ARGUMENT, );
+  // requested_pic_size_ can be adjusted by VDA client. We should update
+  // |requested_pic_size_| by buffers[0].size(). But AMD driver doesn't decode
+  // frames correctly if the surface stride is different from the width of a
+  // coded size.
+  // TODO(b/139460315): Save buffers[0].size() as |adjusted_size_| once the
+  // AMD driver issue is resolved.
+
+  va_surface_format_ = GetVaFormatForVideoCodecProfile(profile_);
+  std::vector<VASurfaceID> va_surface_ids;
+  scoped_refptr<VaapiWrapper> vaapi_wrapper_for_picture = vaapi_wrapper_;
+
+  const bool requires_vpp =
+      vaapi_picture_factory_->NeedsProcessingPipelineForDownloading();
+  // If we aren't in BufferAllocationMode::kNone mode and the VaapiPicture
+  // implementation we get from |vaapi_picture_factory_| requires the video
+  // processing pipeline for downloading the decoded frame from the internal
+  // surface, we need to create a |vpp_vaapi_wrapper_|.
+  if (requires_vpp && buffer_allocation_mode_ != BufferAllocationMode::kNone) {
+    if (!vpp_vaapi_wrapper_) {
+      vpp_vaapi_wrapper_ = VaapiWrapper::Create(
+          VaapiWrapper::kVideoProcess, VAProfileNone,
+          EncryptionScheme::kUnencrypted,
+          base::BindRepeating(
+              &ReportVaapiErrorToUMA,
+              "Media.VaapiVideoDecodeAccelerator.Vpp.VAAPIError"),
+          /*enforce_sequence_affinity=*/false);
+      RETURN_AND_NOTIFY_ON_FAILURE(vpp_vaapi_wrapper_,
+                                   "Failed to initialize VppVaapiWrapper",
+                                   PLATFORM_FAILURE, );
+      // Size is irrelevant for a VPP context.
+      RETURN_AND_NOTIFY_ON_FAILURE(
+          vpp_vaapi_wrapper_->CreateContext(gfx::Size()),
+          "Failed to create Context", PLATFORM_FAILURE, );
+    }
+    vaapi_wrapper_for_picture = vpp_vaapi_wrapper_;
+  }
+
+  for (size_t i = 0; i < buffers.size(); ++i) {
+    // TODO(b/139460315): Create with buffers[i] once the AMD driver issue is
+    // resolved.
+    PictureBuffer buffer = buffers[i];
+    buffer.set_size(requested_pic_size_);
+
+    // Note that the |size_to_bind| is not relevant in IMPORT mode.
+    const gfx::Size size_to_bind =
+        (output_mode_ == Config::OutputMode::ALLOCATE)
+            ? GetRectSizeFromOrigin(requested_visible_rect_)
+            : gfx::Size();
+
+    std::unique_ptr<VaapiPicture> picture = vaapi_picture_factory_->Create(
+        vaapi_wrapper_for_picture, make_context_current_cb_, bind_image_cb_,
+        buffer, size_to_bind);
+    RETURN_AND_NOTIFY_ON_FAILURE(picture, "Failed creating a VaapiPicture",
+                                 PLATFORM_FAILURE, );
+
+    if (output_mode_ == Config::OutputMode::ALLOCATE) {
+      RETURN_AND_NOTIFY_ON_STATUS(
+          picture->Allocate(vaapi_picture_factory_->GetBufferFormat()), );
+
+      available_picture_buffers_.push_back(buffers[i].id());
+      VASurfaceID va_surface_id = picture->va_surface_id();
+      if (va_surface_id != VA_INVALID_ID)
+        va_surface_ids.push_back(va_surface_id);
+    }
+
+    DCHECK(!base::Contains(pictures_, buffers[i].id()));
+    pictures_[buffers[i].id()] = std::move(picture);
+
+    surfaces_available_.Signal();
+  }
+
+  base::RepeatingCallback<void(VASurfaceID)> va_surface_release_cb;
+
+  // If we aren't in BufferAllocationMode::kNone, we use |va_surface_ids| for
+  // decode, otherwise ask |vaapi_wrapper_| to allocate them for us.
+  if (buffer_allocation_mode_ == BufferAllocationMode::kNone) {
+    DCHECK(!va_surface_ids.empty());
+    RETURN_AND_NOTIFY_ON_FAILURE(
+        vaapi_wrapper_->CreateContext(requested_pic_size_),
+        "Failed creating VA Context", PLATFORM_FAILURE, );
+    DCHECK_EQ(va_surface_ids.size(), buffers.size());
+
+    va_surface_release_cb = base::DoNothing();
+  } else {
+    const size_t requested_num_surfaces =
+        IsBufferAllocationModeReducedOrSuperReduced()
+            ? requested_num_reference_frames_
+            : pictures_.size();
+    CHECK_NE(requested_num_surfaces, 0u);
+    va_surface_ids.clear();
+
+    RETURN_AND_NOTIFY_ON_FAILURE(
+        vaapi_wrapper_->CreateContextAndSurfaces(
+            va_surface_format_, requested_pic_size_,
+            {VaapiWrapper::SurfaceUsageHint::kVideoDecoder},
+            requested_num_surfaces, &va_surface_ids),
+        "Failed creating VA Surfaces", PLATFORM_FAILURE, );
+
+    va_surface_release_cb =
+        base::BindRepeating(&VaapiWrapper::DestroySurface, vaapi_wrapper_);
+  }
+
+  for (const VASurfaceID va_surface_id : va_surface_ids) {
+    available_va_surfaces_.emplace_back(std::make_unique<ScopedVASurfaceID>(
+        va_surface_id, va_surface_release_cb));
+  }
+
+  // Resume DecodeTask if it is still in decoding state.
+  if (state_ == kDecoding) {
+    decoder_thread_task_runner_->PostTask(
+        FROM_HERE, base::BindOnce(&VaapiVideoDecodeAccelerator::DecodeTask,
+                                  base::Unretained(this)));
+  }
+}
+
+#if BUILDFLAG(IS_OZONE)
+void VaapiVideoDecodeAccelerator::ImportBufferForPicture(
+    int32_t picture_buffer_id,
+    VideoPixelFormat pixel_format,
+    gfx::GpuMemoryBufferHandle gpu_memory_buffer_handle) {
+  VLOGF(2) << "Importing picture id: " << picture_buffer_id;
+  DCHECK(task_runner_->BelongsToCurrentThread());
+
+  if (output_mode_ != Config::OutputMode::IMPORT) {
+    LOG(ERROR) << "Cannot import in non-import mode";
+    NotifyError(INVALID_ARGUMENT);
+    return;
+  }
+
+  {
+    base::AutoLock auto_lock(lock_);
+    if (!pictures_.count(picture_buffer_id)) {
+      // It's possible that we've already posted a DismissPictureBuffer for this
+      // picture, but it has not yet executed when this ImportBufferForPicture
+      // was posted to us by the client. In that case just ignore this (we've
+      // already dismissed it and accounted for that).
+      DVLOGF(3) << "got picture id=" << picture_buffer_id
+                << " not in use (anymore?).";
+      return;
+    }
+
+    auto buffer_format = VideoPixelFormatToGfxBufferFormat(pixel_format);
+    if (!buffer_format) {
+      LOG(ERROR) << "Unsupported format: " << pixel_format;
+      NotifyError(INVALID_ARGUMENT);
+      return;
+    }
+
+    VaapiPicture* picture = pictures_[picture_buffer_id].get();
+    if (!picture->ImportGpuMemoryBufferHandle(
+            *buffer_format, std::move(gpu_memory_buffer_handle))) {
+      // ImportGpuMemoryBufferHandle will close the handles even on failure, so
+      // we don't need to do this ourselves.
+      LOG(ERROR) << "Failed to import GpuMemoryBufferHandle";
+      NotifyError(PLATFORM_FAILURE);
+      return;
+    }
+  }
+
+  ReusePictureBuffer(picture_buffer_id);
+}
+#endif
+
+void VaapiVideoDecodeAccelerator::ReusePictureBuffer(
+    int32_t picture_buffer_id) {
+  DVLOGF(4) << "picture id=" << picture_buffer_id;
+  DCHECK(task_runner_->BelongsToCurrentThread());
+  TRACE_EVENT1("media,gpu", "VAVDA::ReusePictureBuffer", "Picture id",
+               picture_buffer_id);
+
+  {
+    base::AutoLock auto_lock(lock_);
+
+    if (!pictures_.count(picture_buffer_id)) {
+      // It's possible that we've already posted a DismissPictureBuffer for this
+      // picture, but it has not yet executed when this ReusePictureBuffer
+      // was posted to us by the client. In that case just ignore this (we've
+      // already dismissed it and accounted for that).
+      DVLOGF(3) << "got picture id=" << picture_buffer_id
+                << " not in use (anymore?).";
+      return;
+    }
+
+    available_picture_buffers_.push_back(picture_buffer_id);
+    TRACE_COUNTER_ID2("media,gpu", "Vaapi frames at client", this, "used",
+                      pictures_.size() - available_picture_buffers_.size(),
+                      "available", available_picture_buffers_.size());
+  }
+
+  TryOutputPicture();
+}
+
+void VaapiVideoDecodeAccelerator::FlushTask() {
+  VLOGF(2);
+  DCHECK(decoder_thread_task_runner_->BelongsToCurrentThread());
+  DCHECK(curr_input_buffer_ && curr_input_buffer_->IsFlushRequest());
+
+  curr_input_buffer_.reset();
+
+  // First flush all the pictures that haven't been outputted, notifying the
+  // client to output them.
+  bool res = decoder_->Flush();
+  RETURN_AND_NOTIFY_ON_FAILURE(res, "Failed flushing the decoder.",
+                               PLATFORM_FAILURE, );
+
+  // Put the decoder in idle state, ready to resume.
+  decoder_->Reset();
+
+  task_runner_->PostTask(
+      FROM_HERE,
+      base::BindOnce(&VaapiVideoDecodeAccelerator::FinishFlush, weak_this_));
+}
+
+void VaapiVideoDecodeAccelerator::Flush() {
+  VLOGF(2) << "Got flush request";
+  DCHECK(task_runner_->BelongsToCurrentThread());
+
+  QueueInputBuffer(DecoderBuffer::CreateEOSBuffer(), -1);
+}
+
+void VaapiVideoDecodeAccelerator::FinishFlush() {
+  VLOGF(2);
+  DCHECK(task_runner_->BelongsToCurrentThread());
+
+  finish_flush_pending_ = false;
+
+  base::AutoLock auto_lock(lock_);
+  if (state_ != kDecoding) {
+    DCHECK(state_ == kDestroying || state_ == kResetting) << state_;
+    return;
+  }
+
+  // Still waiting for textures from client to finish outputting all pending
+  // frames. Try again later.
+  if (!pending_output_cbs_.empty()) {
+    finish_flush_pending_ = true;
+    return;
+  }
+
+  // Resume decoding if necessary.
+  if (input_buffers_.empty()) {
+    state_ = kIdle;
+  } else {
+    decoder_thread_task_runner_->PostTask(
+        FROM_HERE, base::BindOnce(&VaapiVideoDecodeAccelerator::DecodeTask,
+                                  base::Unretained(this)));
+  }
+
+  task_runner_->PostTask(FROM_HERE,
+                         base::BindOnce(&Client::NotifyFlushDone, client_));
+}
+
+void VaapiVideoDecodeAccelerator::ResetTask() {
+  VLOGF(2);
+  DCHECK(decoder_thread_task_runner_->BelongsToCurrentThread());
+
+  // All the decoding tasks from before the reset request from client are done
+  // by now, as this task was scheduled after them and client is expected not
+  // to call Decode() after Reset() and before NotifyResetDone.
+  decoder_->Reset();
+
+  base::AutoLock auto_lock(lock_);
+
+  // Return current input buffer, if present.
+  if (curr_input_buffer_)
+    ReturnCurrInputBuffer_Locked();
+
+  // And let client know that we are done with reset.
+  task_runner_->PostTask(
+      FROM_HERE,
+      base::BindOnce(&VaapiVideoDecodeAccelerator::FinishReset, weak_this_));
+}
+
+void VaapiVideoDecodeAccelerator::Reset() {
+  VLOGF(2) << "Got reset request";
+  DCHECK(task_runner_->BelongsToCurrentThread());
+
+  // This will make any new decode tasks exit early.
+  base::AutoLock auto_lock(lock_);
+  state_ = kResetting;
+  finish_flush_pending_ = false;
+
+  // Drop all remaining input buffers, if present.
+  while (!input_buffers_.empty())
+    input_buffers_.pop();
+  TRACE_COUNTER1("media,gpu", "Vaapi input buffers", input_buffers_.size());
+
+  decoder_thread_task_runner_->PostTask(
+      FROM_HERE, base::BindOnce(&VaapiVideoDecodeAccelerator::ResetTask,
+                                base::Unretained(this)));
+
+  input_ready_.Signal();
+  surfaces_available_.Signal();
+}
+
+void VaapiVideoDecodeAccelerator::FinishReset() {
+  VLOGF(2);
+  DCHECK(task_runner_->BelongsToCurrentThread());
+  base::AutoLock auto_lock(lock_);
+
+  if (state_ != kResetting) {
+    DCHECK(state_ == kDestroying || state_ == kUninitialized) << state_;
+    return;  // We could've gotten destroyed already.
+  }
+
+  // Drop pending outputs.
+  while (!pending_output_cbs_.empty())
+    pending_output_cbs_.pop();
+
+  if (awaiting_va_surfaces_recycle_) {
+    // Decoder requested a new surface set while we were waiting for it to
+    // finish the last DecodeTask, running at the time of Reset().
+    // Let the surface set change finish first before resetting.
+    task_runner_->PostTask(
+        FROM_HERE,
+        base::BindOnce(&VaapiVideoDecodeAccelerator::FinishReset, weak_this_));
+    return;
+  }
+
+  state_ = kIdle;
+
+  task_runner_->PostTask(FROM_HERE,
+                         base::BindOnce(&Client::NotifyResetDone, client_));
+
+  // The client might have given us new buffers via Decode() while we were
+  // resetting and might be waiting for our move, and not call Decode() anymore
+  // until we return something. Post a DecodeTask() so that we won't
+  // sleep forever waiting for Decode() in that case. Having two of them
+  // in the pipe is harmless, the additional one will return as soon as it sees
+  // that we are back in kDecoding state.
+  if (!input_buffers_.empty()) {
+    state_ = kDecoding;
+    decoder_thread_task_runner_->PostTask(
+        FROM_HERE, base::BindOnce(&VaapiVideoDecodeAccelerator::DecodeTask,
+                                  base::Unretained(this)));
+  }
+}
+
+void VaapiVideoDecodeAccelerator::Cleanup() {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+
+  base::AutoLock auto_lock(lock_);
+  if (state_ == kUninitialized || state_ == kDestroying)
+    return;
+
+  VLOGF(2) << "Destroying VAVDA";
+  state_ = kDestroying;
+
+  // Call DismissPictureBuffer() to notify |client_| that the picture buffers
+  // are no longer used and thus |client_| shall release them. If |client_| has
+  // been invalidated in NotifyError(),|client_| will be destroyed shortly. The
+  // destruction should release all the PictureBuffers.
+  if (client_) {
+    for (const auto& id_and_picture : pictures_)
+      client_->DismissPictureBuffer(id_and_picture.first);
+  }
+  pictures_.clear();
+
+  client_ptr_factory_.reset();
+  weak_this_factory_.InvalidateWeakPtrs();
+
+  // TODO(mcasas): consider deleting |decoder_| on
+  // |decoder_thread_task_runner_|, https://crbug.com/789160.
+
+  // Signal all potential waiters on the decoder_thread_, let them early-exit,
+  // as we've just moved to the kDestroying state, and wait for all tasks
+  // to finish.
+  input_ready_.Signal();
+  surfaces_available_.Signal();
+  {
+    base::AutoUnlock auto_unlock(lock_);
+    decoder_thread_.Stop();
+  }
+  if (buffer_allocation_mode_ != BufferAllocationMode::kNone)
+    available_va_surfaces_.clear();
+
+  // Notify |decoder_delegate_| of an imminent VAContextID destruction, so it
+  // can destroy any internal structures making use of it. At this point
+  // |decoder_thread_| is stopped so we can access |decoder_delegate_| from
+  // |task_runner_|.
+  decoder_delegate_->OnVAContextDestructionSoon();
+  vaapi_wrapper_->DestroyContext();
+
+  if (vpp_vaapi_wrapper_)
+    vpp_vaapi_wrapper_->DestroyContext();
+  state_ = kUninitialized;
+}
+
+void VaapiVideoDecodeAccelerator::Destroy() {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+  Cleanup();
+  delete this;
+}
+
+bool VaapiVideoDecodeAccelerator::TryToSetupDecodeOnSeparateSequence(
+    const base::WeakPtr<Client>& decode_client,
+    const scoped_refptr<base::SequencedTaskRunner>& decode_task_runner) {
+  return false;
+}
+
+void VaapiVideoDecodeAccelerator::SurfaceReady(
+    scoped_refptr<VASurface> dec_surface,
+    int32_t bitstream_id,
+    const gfx::Rect& visible_rect,
+    const VideoColorSpace& color_space) {
+  if (!task_runner_->BelongsToCurrentThread()) {
+    task_runner_->PostTask(
+        FROM_HERE, base::BindOnce(&VaapiVideoDecodeAccelerator::SurfaceReady,
+                                  weak_this_, std::move(dec_surface),
+                                  bitstream_id, visible_rect, color_space));
+    return;
+  }
+
+  DCHECK(!awaiting_va_surfaces_recycle_);
+
+  {
+    base::AutoLock auto_lock(lock_);
+    // Drop any requests to output if we are resetting or being destroyed.
+    if (state_ == kResetting || state_ == kDestroying)
+      return;
+  }
+  pending_output_cbs_.push(base::BindOnce(
+      &VaapiVideoDecodeAccelerator::OutputPicture, weak_this_,
+      std::move(dec_surface), bitstream_id, visible_rect, color_space));
+
+  TryOutputPicture();
+}
+
+scoped_refptr<VASurface> VaapiVideoDecodeAccelerator::CreateSurface() {
+  DCHECK(decoder_thread_task_runner_->BelongsToCurrentThread());
+  base::AutoLock auto_lock(lock_);
+
+  if (available_va_surfaces_.empty())
+    return nullptr;
+
+  DCHECK_NE(VA_INVALID_ID, va_surface_format_);
+  DCHECK(!awaiting_va_surfaces_recycle_);
+  if (buffer_allocation_mode_ != BufferAllocationMode::kNone) {
+    auto va_surface_id = std::move(available_va_surfaces_.front());
+    const VASurfaceID id = va_surface_id->id();
+    available_va_surfaces_.pop_front();
+
+    TRACE_COUNTER_ID2("media,gpu", "Vaapi VASurfaceIDs", this, "used",
+                      (IsBufferAllocationModeReducedOrSuperReduced()
+                           ? requested_num_reference_frames_
+                           : pictures_.size()) -
+                          available_va_surfaces_.size(),
+                      "available", available_va_surfaces_.size());
+
+    return new VASurface(
+        id, requested_pic_size_, va_surface_format_,
+        base::BindOnce(va_surface_recycle_cb_, std::move(va_surface_id)));
+  }
+
+  // Find the first |available_va_surfaces_| id such that the associated
+  // |pictures_| entry is marked as |available_picture_buffers_|. In practice,
+  // we will quickly find an available |va_surface_id|.
+  for (auto it = available_va_surfaces_.begin();
+       it != available_va_surfaces_.end(); ++it) {
+    const VASurfaceID va_surface_id = (*it)->id();
+    for (const auto& id_and_picture : pictures_) {
+      if (id_and_picture.second->va_surface_id() == va_surface_id &&
+          base::Contains(available_picture_buffers_, id_and_picture.first)) {
+        // Remove |va_surface_id| from the list of availables, and use the id
+        // to return a new VASurface.
+        auto va_surface = std::move(*it);
+        available_va_surfaces_.erase(it);
+        return new VASurface(
+            va_surface_id, requested_pic_size_, va_surface_format_,
+            base::BindOnce(va_surface_recycle_cb_, std::move(va_surface)));
+      }
+    }
+  }
+  return nullptr;
+}
+
+void VaapiVideoDecodeAccelerator::RecycleVASurface(
+    std::unique_ptr<ScopedVASurfaceID> va_surface,
+    // We don't use |va_surface_id| but it must be here because this method is
+    // bound as VASurface::ReleaseCB.
+    VASurfaceID /*va_surface_id*/) {
+  DCHECK(task_runner_->BelongsToCurrentThread());
+
+  {
+    base::AutoLock auto_lock(lock_);
+    available_va_surfaces_.push_back(std::move(va_surface));
+
+    if (buffer_allocation_mode_ != BufferAllocationMode::kNone) {
+      TRACE_COUNTER_ID2("media,gpu", "Vaapi VASurfaceIDs", this, "used",
+                        (IsBufferAllocationModeReducedOrSuperReduced()
+                             ? requested_num_reference_frames_
+                             : pictures_.size()) -
+                            available_va_surfaces_.size(),
+                        "available", available_va_surfaces_.size());
+    }
+    surfaces_available_.Signal();
+  }
+
+  TryOutputPicture();
+}
+
+// static
+VideoDecodeAccelerator::SupportedProfiles
+VaapiVideoDecodeAccelerator::GetSupportedProfiles() {
+  VideoDecodeAccelerator::SupportedProfiles profiles =
+      VaapiWrapper::GetSupportedDecodeProfiles();
+  // VaVDA never supported VP9 Profile 2, AV1 and HEVC, but VaapiWrapper does.
+  // Filter them out.
+  base::EraseIf(profiles, [](const auto& profile) {
+    VideoCodec codec = VideoCodecProfileToVideoCodec(profile.profile);
+    return profile.profile == VP9PROFILE_PROFILE2 ||
+           codec == VideoCodec::kAV1 || codec == VideoCodec::kHEVC;
+  });
+  return profiles;
+}
+
+VaapiVideoDecodeAccelerator::BufferAllocationMode
+VaapiVideoDecodeAccelerator::DecideBufferAllocationMode() {
+#if BUILDFLAG(USE_VAAPI_X11)
+  // The IMPORT mode is used for Android on Chrome OS, so this doesn't apply
+  // here.
+  DCHECK_NE(output_mode_, VideoDecodeAccelerator::Config::OutputMode::IMPORT);
+  // TODO(crbug/1116701): get video decode acceleration working with ozone.
+  // For H.264 on older devices, another +1 is experimentally needed for
+  // high-to-high resolution changes.
+  // TODO(mcasas): Figure out why and why only H264, see crbug.com/912295 and
+  // http://crrev.com/c/1363807/9/media/gpu/h264_decoder.cc#1449.
+  if (profile_ >= H264PROFILE_MIN && profile_ <= H264PROFILE_MAX)
+    return BufferAllocationMode::kReduced;
+  return BufferAllocationMode::kSuperReduced;
+#else
+  // TODO(crbug.com/912295): Enable a better BufferAllocationMode for IMPORT
+  // |output_mode_| as well.
+  if (output_mode_ == VideoDecodeAccelerator::Config::OutputMode::IMPORT)
+    return BufferAllocationMode::kNormal;
+
+  // On Gemini Lake, Kaby Lake and later we can pass to libva the client's
+  // PictureBuffers to decode onto, which skips the use of the Vpp unit and its
+  // associated format reconciliation copy, avoiding all internal buffer
+  // allocations.
+  // TODO(crbug.com/911754): Enable for VP9 Profile 2.
+  if (IsGeminiLakeOrLater() &&
+      (profile_ == VP9PROFILE_PROFILE0 || profile_ == VP8PROFILE_ANY ||
+       (profile_ >= H264PROFILE_MIN && profile_ <= H264PROFILE_MAX))) {
+    // Add one to the reference frames for the one being currently egressed, and
+    // an extra allocation for both |client_| and |decoder_|, see
+    // crrev.com/c/1576560.
+    if (profile_ == VP8PROFILE_ANY)
+      num_extra_pics_ = 3;
+    return BufferAllocationMode::kNone;
+  }
+
+  // For H.264 on older devices, another +1 is experimentally needed for
+  // high-to-high resolution changes.
+  // TODO(mcasas): Figure out why and why only H264, see crbug.com/912295 and
+  // http://crrev.com/c/1363807/9/media/gpu/h264_decoder.cc#1449.
+  if (profile_ >= H264PROFILE_MIN && profile_ <= H264PROFILE_MAX)
+    return BufferAllocationMode::kReduced;
+
+  // If we're here, we have to use the Vpp unit and allocate buffers for
+  // |decoder_|; usually we'd have to allocate the |decoder_|s
+  // GetRequiredNumOfPictures() internally, we can allocate just |decoder_|s
+  // GetNumReferenceFrames() + 1. Moreover, we also request the |client_| to
+  // allocate less than the usual |decoder_|s GetRequiredNumOfPictures().
+  return BufferAllocationMode::kSuperReduced;
+#endif
+}
+
+bool VaapiVideoDecodeAccelerator::IsBufferAllocationModeReducedOrSuperReduced()
+    const {
+  return buffer_allocation_mode_ == BufferAllocationMode::kSuperReduced ||
+         buffer_allocation_mode_ == BufferAllocationMode::kReduced;
+}
+
+bool VaapiVideoDecodeAccelerator::OnMemoryDump(
+    const base::trace_event::MemoryDumpArgs& args,
+    base::trace_event::ProcessMemoryDump* pmd) {
+  using base::trace_event::MemoryAllocatorDump;
+  base::AutoLock auto_lock(lock_);
+  if (buffer_allocation_mode_ == BufferAllocationMode::kNone ||
+      !requested_num_reference_frames_) {
+    return false;
+  }
+
+  auto dump_name = base::StringPrintf("gpu/vaapi/decoder/0x%" PRIxPTR,
+                                      reinterpret_cast<uintptr_t>(this));
+  MemoryAllocatorDump* dump = pmd->CreateAllocatorDump(dump_name);
+
+  constexpr float kNumBytesPerPixelYUV420 = 12.0 / 8;
+  constexpr float kNumBytesPerPixelYUV420_10bpp = 2 * kNumBytesPerPixelYUV420;
+  DCHECK(va_surface_format_ == VA_RT_FORMAT_YUV420 ||
+         va_surface_format_ == VA_RT_FORMAT_YUV420_10BPP);
+  const float va_surface_bytes_per_pixel =
+      va_surface_format_ == VA_RT_FORMAT_YUV420 ? kNumBytesPerPixelYUV420
+                                                : kNumBytesPerPixelYUV420_10bpp;
+  // Report |requested_num_surfaces| and the associated memory size. The
+  // calculated size is an estimation since we don't know the internal VA
+  // strides, texture compression, headers, etc, but is a good lower boundary.
+  const size_t requested_num_surfaces =
+      IsBufferAllocationModeReducedOrSuperReduced()
+          ? requested_num_reference_frames_
+          : pictures_.size();
+  dump->AddScalar(MemoryAllocatorDump::kNameSize,
+                  MemoryAllocatorDump::kUnitsBytes,
+                  static_cast<uint64_t>(requested_num_surfaces *
+                                        requested_pic_size_.GetArea() *
+                                        va_surface_bytes_per_pixel));
+  dump->AddScalar(MemoryAllocatorDump::kNameObjectCount,
+                  MemoryAllocatorDump::kUnitsObjects,
+                  static_cast<uint64_t>(requested_num_surfaces));
+
+  return true;
+}
+
+}  // namespace media
diff --git a/media/gpu/vaapi/vaapi_video_decode_accelerator.h b/media/gpu/vaapi/vaapi_video_decode_accelerator.h
new file mode 100644
index 0000000..8962964
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_video_decode_accelerator.h
@@ -0,0 +1,366 @@
+// Copyright 2012 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+//
+// This file contains an implementation of VideoDecoderAccelerator
+// that utilizes hardware video decoder present on Intel CPUs.
+
+#ifndef MEDIA_GPU_VAAPI_VAAPI_VIDEO_DECODE_ACCELERATOR_H_
+#define MEDIA_GPU_VAAPI_VAAPI_VIDEO_DECODE_ACCELERATOR_H_
+
+#include <stddef.h>
+#include <stdint.h>
+
+#include <list>
+#include <map>
+#include <memory>
+#include <utility>
+#include <vector>
+
+#include "base/containers/queue.h"
+#include "base/containers/small_map.h"
+#include "base/memory/raw_ptr.h"
+#include "base/memory/weak_ptr.h"
+#include "base/synchronization/condition_variable.h"
+#include "base/synchronization/lock.h"
+#include "base/task/single_thread_task_runner.h"
+#include "base/thread_annotations.h"
+#include "base/threading/thread.h"
+#include "base/trace_event/memory_dump_provider.h"
+#include "build/build_config.h"
+#include "media/base/bitstream_buffer.h"
+#include "media/gpu/decode_surface_handler.h"
+#include "media/gpu/gpu_video_decode_accelerator_helpers.h"
+#include "media/gpu/media_gpu_export.h"
+#include "media/gpu/vaapi/vaapi_picture_factory.h"
+#include "media/gpu/vaapi/vaapi_wrapper.h"
+#include "media/video/picture.h"
+#include "media/video/video_decode_accelerator.h"
+
+namespace gl {
+class GLImage;
+}
+
+namespace media {
+
+class AcceleratedVideoDecoder;
+template <typename T>
+class ScopedID;
+class VaapiVideoDecoderDelegate;
+class VaapiPicture;
+
+// Class to provide video decode acceleration for Intel systems with hardware
+// support for it, and on which libva is available.
+// Decoding tasks are performed in a separate decoding thread.
+//
+// Threading/life-cycle: this object is created & destroyed on the GPU
+// ChildThread.  A few methods on it are called on the decoder thread which is
+// stopped during |this->Destroy()|, so any tasks posted to the decoder thread
+// can assume |*this| is still alive.  See |weak_this_| below for more details.
+class MEDIA_GPU_EXPORT VaapiVideoDecodeAccelerator
+    : public VideoDecodeAccelerator,
+      public DecodeSurfaceHandler<VASurface>,
+      public base::trace_event::MemoryDumpProvider {
+ public:
+  VaapiVideoDecodeAccelerator(
+      const MakeGLContextCurrentCallback& make_context_current_cb,
+      const BindGLImageCallback& bind_image_cb);
+
+  VaapiVideoDecodeAccelerator(const VaapiVideoDecodeAccelerator&) = delete;
+  VaapiVideoDecodeAccelerator& operator=(const VaapiVideoDecodeAccelerator&) =
+      delete;
+
+  ~VaapiVideoDecodeAccelerator() override;
+
+  // VideoDecodeAccelerator implementation.
+  bool Initialize(const Config& config, Client* client) override;
+  void Decode(BitstreamBuffer bitstream_buffer) override;
+  void Decode(scoped_refptr<DecoderBuffer> buffer,
+              int32_t bitstream_id) override;
+  void AssignPictureBuffers(const std::vector<PictureBuffer>& buffers) override;
+#if BUILDFLAG(IS_OZONE)
+  void ImportBufferForPicture(
+      int32_t picture_buffer_id,
+      VideoPixelFormat pixel_format,
+      gfx::GpuMemoryBufferHandle gpu_memory_buffer_handle) override;
+#endif
+  void ReusePictureBuffer(int32_t picture_buffer_id) override;
+  void Flush() override;
+  void Reset() override;
+  void Destroy() override;
+  bool TryToSetupDecodeOnSeparateSequence(
+      const base::WeakPtr<Client>& decode_client,
+      const scoped_refptr<base::SequencedTaskRunner>& decode_task_runner)
+      override;
+
+  static VideoDecodeAccelerator::SupportedProfiles GetSupportedProfiles();
+
+  // DecodeSurfaceHandler implementation.
+  scoped_refptr<VASurface> CreateSurface() override;
+  void SurfaceReady(scoped_refptr<VASurface> va_surface,
+                    int32_t bitstream_id,
+                    const gfx::Rect& visible_rect,
+                    const VideoColorSpace& color_space) override;
+
+  // base::trace_event::MemoryDumpProvider implementation.
+  bool OnMemoryDump(const base::trace_event::MemoryDumpArgs& args,
+                    base::trace_event::ProcessMemoryDump* pmd) override;
+
+ private:
+  friend class VaapiVideoDecodeAcceleratorTest;
+
+  // An input buffer with id provided by the client and awaiting consumption.
+  class InputBuffer;
+  // A self-cleaning VASurfaceID.
+  using ScopedVASurfaceID = ScopedID<VASurfaceID>;
+
+  // Notify the client that an error has occurred and decoding cannot continue.
+  void NotifyError(Error error);
+  void NotifyStatus(VaapiStatus status);
+
+  // Queue a input buffer for decode.
+  void QueueInputBuffer(scoped_refptr<DecoderBuffer> buffer,
+                        int32_t bitstream_id);
+
+  // Gets a new |current_input_buffer_| from |input_buffers_| and sets it up in
+  // |decoder_|. This method will sleep if no |input_buffers_| are available.
+  // Returns true if a new buffer has been set up, false if an early exit has
+  // been requested (due to initiated reset/flush/destroy).
+  bool GetCurrInputBuffer_Locked() EXCLUSIVE_LOCKS_REQUIRED(lock_);
+
+  // Signals the client that |curr_input_buffer_| has been read and can be
+  // returned. Will also release the mapping.
+  void ReturnCurrInputBuffer_Locked() EXCLUSIVE_LOCKS_REQUIRED(lock_);
+
+  // Waits for more surfaces to become available. Returns true once they do or
+  // false if an early exit has been requested (due to an initiated
+  // reset/flush/destroy).
+  bool WaitForSurfaces_Locked() EXCLUSIVE_LOCKS_REQUIRED(lock_);
+
+  // Continue decoding given input buffers and sleep waiting for input/output
+  // as needed. Will exit if a new set of surfaces or reset/flush/destroy
+  // is requested.
+  void DecodeTask();
+
+  // Scheduled after receiving a flush request and executed after the current
+  // decoding task finishes decoding pending inputs. Makes the decoder return
+  // all remaining output pictures and puts it in an idle state, ready
+  // to resume if needed and schedules a FinishFlush.
+  void FlushTask();
+
+  // Scheduled by the FlushTask after decoder is flushed to put VAVDA into idle
+  // state and notify the client that flushing has been finished.
+  void FinishFlush();
+
+  // Scheduled after receiving a reset request and executed after the current
+  // decoding task finishes decoding the current frame. Puts the decoder into
+  // an idle state, ready to resume if needed, discarding decoded but not yet
+  // outputted pictures (decoder keeps ownership of their associated picture
+  // buffers). Schedules a FinishReset afterwards.
+  void ResetTask();
+
+  // Scheduled by ResetTask after it's done putting VAVDA into an idle state.
+  // Drops remaining input buffers and notifies the client that reset has been
+  // finished.
+  void FinishReset();
+
+  // Helper for Destroy(), doing all the actual work except for deleting self.
+  void Cleanup();
+
+  // Get a usable framebuffer configuration for use in binding textures
+  // or return false on failure.
+  bool InitializeFBConfig();
+
+  // Callback to be executed once we have a |va_surface| to be output and an
+  // available VaapiPicture in |available_picture_buffers_| for output. Puts
+  // contents of |va_surface| into the latter, releases the surface and passes
+  // the resulting picture to |client_| along with |visible_rect|.
+  void OutputPicture(scoped_refptr<VASurface> va_surface,
+                     int32_t input_id,
+                     gfx::Rect visible_rect,
+                     const VideoColorSpace& picture_color_space);
+
+  // Try to OutputPicture() if we have both a ready surface and picture.
+  void TryOutputPicture();
+
+  // Called when a VASurface is no longer in use by |decoder_| nor |client_|.
+  // Returns it to |available_va_surfaces_|. |va_surface_id| is not used but it
+  // must be here to bind this method as VASurface::ReleaseCB.
+  void RecycleVASurface(std::unique_ptr<ScopedVASurfaceID> va_surface,
+                        VASurfaceID va_surface_id);
+
+  // Request a new set of |num_pics| PictureBuffers to be allocated by
+  // |client_|. Up to |num_reference_frames| out of |num_pics_| might be needed
+  // by |decoder_|.
+  void InitiateSurfaceSetChange(size_t num_pics,
+                                gfx::Size size,
+                                size_t num_reference_frames,
+                                const gfx::Rect& visible_rect);
+
+  // Check if the surfaces have been released or post ourselves for later.
+  void TryFinishSurfaceSetChange();
+
+  // Different modes of internal buffer allocations.
+  enum class BufferAllocationMode {
+    // Only using |client_|s provided PictureBuffers, none internal.
+    kNone,
+
+    // Using a reduced amount of |client_|s provided PictureBuffers and
+    // |decoder_|s GetNumReferenceFrames() internallly.
+    kSuperReduced,
+
+    // Similar to kSuperReduced, but we have to increase slightly the amount of
+    // PictureBuffers allocated for the |client_|.
+    kReduced,
+
+    // VaapiVideoDecodeAccelerator can work with this mode on all platforms.
+    // Using |client_|s provided PictureBuffers and as many internally
+    // allocated.
+    kNormal,
+  };
+
+  // Decides the concrete buffer allocation mode, depending on the hardware
+  // platform and other parameters.
+  BufferAllocationMode DecideBufferAllocationMode();
+  bool IsBufferAllocationModeReducedOrSuperReduced() const;
+
+  // VAVDA state.
+  enum State {
+    // Initialize() not called yet or failed.
+    kUninitialized,
+    // DecodeTask running.
+    kDecoding,
+    // Resetting, waiting for decoder to finish current task and cleanup.
+    kResetting,
+    // Idle, decoder in state ready to start/resume decoding.
+    kIdle,
+    // Destroying, waiting for the decoder to finish current task.
+    kDestroying,
+  };
+
+  base::Lock lock_;
+  State state_ GUARDED_BY(lock_);
+  // Only used on |task_runner_|.
+  Config::OutputMode output_mode_;
+
+  // Queue of available InputBuffers.
+  base::queue<std::unique_ptr<InputBuffer>> input_buffers_ GUARDED_BY(lock_);
+  // Signalled when input buffers are queued onto |input_buffers_| queue.
+  base::ConditionVariable input_ready_;
+
+  // Current input buffer at decoder. Only used on |decoder_thread_task_runner_|
+  std::unique_ptr<InputBuffer> curr_input_buffer_;
+
+  // Only used on |task_runner_|.
+  std::unique_ptr<VaapiPictureFactory> vaapi_picture_factory_;
+
+  // The following variables are constructed/initialized in Initialize() when
+  // the codec information is received. |vaapi_wrapper_| is thread safe.
+  scoped_refptr<VaapiWrapper> vaapi_wrapper_;
+  // Only used on |decoder_thread_task_runner_|.
+  std::unique_ptr<AcceleratedVideoDecoder> decoder_;
+  // TODO(crbug.com/1022246): Instead of having the raw pointer here, getting
+  // the pointer from AcceleratedVideoDecoder.
+  raw_ptr<VaapiVideoDecoderDelegate> decoder_delegate_ = nullptr;
+
+  // Filled in during Initialize().
+  BufferAllocationMode buffer_allocation_mode_;
+
+  // VaapiWrapper for VPP (Video Post Processing). This is used for copying
+  // from a decoded surface to a surface bound to client's PictureBuffer.
+  scoped_refptr<VaapiWrapper> vpp_vaapi_wrapper_;
+
+  // All allocated VaapiPictures, regardless of their current state. Pictures
+  // are allocated at AssignPictureBuffers() and are kept until dtor or
+  // TryFinishSurfaceSetChange(). Comes after |vaapi_wrapper_| to ensure all
+  // pictures are destroyed before this is destroyed.
+  base::small_map<std::map<int32_t, std::unique_ptr<VaapiPicture>>> pictures_
+      GUARDED_BY(lock_);
+  // List of PictureBuffer ids available to be sent to |client_| via
+  // OutputPicture() (|client_| returns them via ReusePictureBuffer()).
+  std::list<int32_t> available_picture_buffers_ GUARDED_BY(lock_);
+
+  // VASurfaces available and that can be passed to |decoder_| for its use upon
+  // CreateSurface() request (and then returned via RecycleVASurface()).
+  std::list<std::unique_ptr<ScopedVASurfaceID>> available_va_surfaces_
+      GUARDED_BY(lock_);
+  // Signalled when output surfaces are queued into |available_va_surfaces_|.
+  base::ConditionVariable surfaces_available_;
+  // VASurfaceIDs format, filled in when created.
+  unsigned int va_surface_format_;
+
+  // Pending output requests from the decoder. When it indicates that we should
+  // output a surface and we have an available Picture (i.e. texture) ready
+  // to use, we'll execute the callback passing the Picture. The callback
+  // will put the contents of the surface into the picture and return it to
+  // the client, releasing the surface as well.
+  // If we don't have any available |pictures_| at the time when the decoder
+  // requests output, we'll store the request in this queue for later and run it
+  // once the client gives us more textures via ReusePictureBuffer().
+  // Only used on |task_runner_|.
+  base::queue<base::OnceClosure> pending_output_cbs_;
+
+  // WeakPtr<> pointing to |this| for use in posting tasks from the decoder
+  // thread back to the ChildThread.  Because the decoder thread is a member of
+  // this class, any task running on the decoder thread is guaranteed that this
+  // object is still alive.  As a result, tasks posted from ChildThread to
+  // decoder thread should use base::Unretained(this), and tasks posted from the
+  // decoder thread to the ChildThread should use |weak_this_|.
+  base::WeakPtr<VaapiVideoDecodeAccelerator> weak_this_;
+
+  // Callback used to recycle VASurfaces. Only used on |task_runner_|.
+  base::RepeatingCallback<void(std::unique_ptr<ScopedVASurfaceID>, VASurfaceID)>
+      va_surface_recycle_cb_;
+
+  // To expose client callbacks from VideoDecodeAccelerator. Used only on
+  // |task_runner_|.
+  std::unique_ptr<base::WeakPtrFactory<Client>> client_ptr_factory_;
+  base::WeakPtr<Client> client_;
+
+  // ChildThread's task runner.
+  const scoped_refptr<base::SingleThreadTaskRunner> task_runner_;
+
+  base::Thread decoder_thread_;
+  // Use this to post tasks to |decoder_thread_| instead of
+  // |decoder_thread_.task_runner()| because the latter will be NULL once
+  // |decoder_thread_.Stop()| returns.
+  scoped_refptr<base::SingleThreadTaskRunner> decoder_thread_task_runner_;
+
+  // Whether we are waiting for any |pending_output_cbs_| to be run before
+  // NotifyingFlushDone. Only used on |task_runner_|.
+  bool finish_flush_pending_;
+
+  // Decoder requested a new surface set and we are waiting for all the surfaces
+  // to be returned before we can free them. Only used on |task_runner_|.
+  bool awaiting_va_surfaces_recycle_;
+
+  // Last requested number/resolution/visible rectangle of output
+  // PictureBuffers.
+  size_t requested_num_pics_;
+  gfx::Size requested_pic_size_;
+  gfx::Rect requested_visible_rect_;
+  // Potential extra PictureBuffers to request, used only on
+  // BufferAllocationMode::kNone, see DecideBufferAllocationMode().
+  size_t num_extra_pics_ = 0;
+
+  // Max number of reference frames needed by |decoder_|. Only used on
+  // |task_runner_| and when in BufferAllocationMode::kNone.
+  size_t requested_num_reference_frames_;
+  size_t previously_requested_num_reference_frames_;
+
+  // The video stream's profile.
+  VideoCodecProfile profile_;
+
+  // Callback to make GL context current.
+  MakeGLContextCurrentCallback make_context_current_cb_;
+
+  // Callback to bind a GLImage to a given texture.
+  BindGLImageCallback bind_image_cb_;
+
+  // The WeakPtrFactory for |weak_this_|.
+  base::WeakPtrFactory<VaapiVideoDecodeAccelerator> weak_this_factory_;
+};
+
+}  // namespace media
+
+#endif  // MEDIA_GPU_VAAPI_VAAPI_VIDEO_DECODE_ACCELERATOR_H_
diff --git a/media/gpu/vaapi/vaapi_video_decode_accelerator_unittest.cc b/media/gpu/vaapi/vaapi_video_decode_accelerator_unittest.cc
new file mode 100644
index 0000000..a899c5d
--- /dev/null
+++ b/media/gpu/vaapi/vaapi_video_decode_accelerator_unittest.cc
@@ -0,0 +1,550 @@
+// Copyright 2017 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "media/gpu/vaapi/vaapi_video_decode_accelerator.h"
+
+#include "base/functional/bind.h"
+#include "base/functional/callback_helpers.h"
+#include "base/memory/ptr_util.h"
+#include "base/memory/raw_ptr.h"
+#include "base/run_loop.h"
+#include "base/test/gmock_callback_support.h"
+#include "base/test/task_environment.h"
+#include "base/time/time.h"
+#include "build/build_config.h"
+#include "media/gpu/accelerated_video_decoder.h"
+#include "media/gpu/vaapi/vaapi_picture.h"
+#include "media/gpu/vaapi/vaapi_picture_factory.h"
+#include "media/gpu/vaapi/vaapi_video_decoder_delegate.h"
+#include "media/gpu/vaapi/vaapi_wrapper.h"
+#include "testing/gmock/include/gmock/gmock.h"
+#include "testing/gtest/include/gtest/gtest.h"
+#include "third_party/abseil-cpp/absl/types/optional.h"
+#include "ui/gfx/hdr_metadata.h"
+
+using base::test::RunClosure;
+using ::testing::_;
+using ::testing::DoAll;
+using ::testing::Invoke;
+using ::testing::Return;
+using ::testing::TestWithParam;
+using ::testing::ValuesIn;
+using ::testing::WithArg;
+
+namespace media {
+
+namespace {
+
+struct TestParams {
+  VideoCodecProfile video_codec;
+  bool decode_using_client_picture_buffers;
+};
+
+constexpr int32_t kBitstreamId = 123;
+constexpr size_t kInputSize = 256;
+
+constexpr size_t kNumPictures = 14;
+const gfx::Size kPictureSize(64, 48);
+
+constexpr size_t kNewNumPictures = 13;
+const gfx::Size kNewPictureSize(64, 48);
+
+MATCHER_P2(IsExpectedDecoderBuffer, data_size, decrypt_config, "") {
+  return arg.data_size() == data_size && arg.decrypt_config() == decrypt_config;
+}
+}  // namespace
+
+class MockAcceleratedVideoDecoder : public AcceleratedVideoDecoder {
+ public:
+  MockAcceleratedVideoDecoder() = default;
+  ~MockAcceleratedVideoDecoder() override = default;
+
+  MOCK_METHOD2(SetStream, void(int32_t id, const DecoderBuffer&));
+  MOCK_METHOD0(Flush, bool());
+  MOCK_METHOD0(Reset, void());
+  MOCK_METHOD0(Decode, DecodeResult());
+  MOCK_CONST_METHOD0(GetPicSize, gfx::Size());
+  MOCK_CONST_METHOD0(GetProfile, VideoCodecProfile());
+  MOCK_CONST_METHOD0(GetBitDepth, uint8_t());
+  MOCK_CONST_METHOD0(GetChromaSampling, VideoChromaSampling());
+  MOCK_CONST_METHOD0(GetVideoColorSpace, VideoColorSpace());
+  MOCK_CONST_METHOD0(GetHDRMetadata, absl::optional<gfx::HDRMetadata>());
+  MOCK_CONST_METHOD0(GetVisibleRect, gfx::Rect());
+  MOCK_CONST_METHOD0(GetRequiredNumOfPictures, size_t());
+  MOCK_CONST_METHOD0(GetNumReferenceFrames, size_t());
+};
+
+class MockVaapiWrapper : public VaapiWrapper {
+ public:
+  explicit MockVaapiWrapper(CodecMode mode)
+      : VaapiWrapper(VADisplayStateHandle(), mode) {}
+  MOCK_METHOD5(CreateContextAndSurfaces,
+               bool(unsigned int,
+                    const gfx::Size&,
+                    const std::vector<SurfaceUsageHint>&,
+                    size_t,
+                    std::vector<VASurfaceID>*));
+  MOCK_METHOD1(CreateContext, bool(const gfx::Size&));
+  MOCK_METHOD0(DestroyContext, void());
+  MOCK_METHOD1(DestroySurface, void(VASurfaceID));
+
+ private:
+  ~MockVaapiWrapper() override = default;
+};
+
+class MockVaapiPicture : public VaapiPicture {
+ public:
+  MockVaapiPicture(scoped_refptr<VaapiWrapper> vaapi_wrapper,
+                   const MakeGLContextCurrentCallback& make_context_current_cb,
+                   const BindGLImageCallback& bind_image_cb,
+                   int32_t picture_buffer_id,
+                   const gfx::Size& size,
+                   const gfx::Size& visible_size,
+                   uint32_t texture_id,
+                   uint32_t client_texture_id,
+                   uint32_t texture_target)
+      : VaapiPicture(std::move(vaapi_wrapper),
+                     make_context_current_cb,
+                     bind_image_cb,
+                     picture_buffer_id,
+                     size,
+                     visible_size,
+                     texture_id,
+                     client_texture_id,
+                     texture_target) {}
+  ~MockVaapiPicture() override = default;
+
+  // VaapiPicture implementation.
+  VaapiStatus Allocate(gfx::BufferFormat format) override {
+    return VaapiStatus::Codes::kOk;
+  }
+  bool ImportGpuMemoryBufferHandle(
+      gfx::BufferFormat format,
+      gfx::GpuMemoryBufferHandle gpu_memory_buffer_handle) override {
+    return true;
+  }
+  bool DownloadFromSurface(scoped_refptr<VASurface> va_surface) override {
+    return true;
+  }
+  bool AllowOverlay() const override { return false; }
+  VASurfaceID va_surface_id() const override {
+    // Return any number different from VA_INVALID_ID and VaapiPicture specific.
+    return static_cast<VASurfaceID>(texture_id_);
+  }
+};
+
+class MockVaapiPictureFactory : public VaapiPictureFactory {
+ public:
+  MockVaapiPictureFactory() = default;
+  ~MockVaapiPictureFactory() override = default;
+
+  MOCK_METHOD3(MockCreateVaapiPicture,
+               void(VaapiWrapper*, const gfx::Size&, const gfx::Size&));
+  std::unique_ptr<VaapiPicture> Create(
+      scoped_refptr<VaapiWrapper> vaapi_wrapper,
+      const MakeGLContextCurrentCallback& make_context_current_cb,
+      const BindGLImageCallback& bind_image_cb,
+      const PictureBuffer& picture_buffer,
+      const gfx::Size& visible_size) override {
+    const uint32_t service_texture_id = picture_buffer.service_texture_ids()[0];
+    const uint32_t client_texture_id = picture_buffer.client_texture_ids()[0];
+    MockCreateVaapiPicture(vaapi_wrapper.get(), picture_buffer.size(),
+                           visible_size);
+    return std::make_unique<MockVaapiPicture>(
+        std::move(vaapi_wrapper), make_context_current_cb, bind_image_cb,
+        picture_buffer.id(), picture_buffer.size(), visible_size,
+        service_texture_id, client_texture_id, picture_buffer.texture_target());
+  }
+};
+
+class VaapiVideoDecodeAcceleratorTest : public TestWithParam<TestParams>,
+                                        public VideoDecodeAccelerator::Client {
+ public:
+  VaapiVideoDecodeAcceleratorTest()
+      : vda_(base::BindRepeating([] { return true; }),
+             base::BindRepeating(
+                 [](uint32_t client_texture_id,
+                    uint32_t texture_target,
+                    const scoped_refptr<gl::GLImage>& image) { return true; })),
+        decoder_thread_("VaapiVideoDecodeAcceleratorTestThread"),
+        mock_decoder_(new ::testing::StrictMock<MockAcceleratedVideoDecoder>),
+        mock_vaapi_picture_factory_(new MockVaapiPictureFactory()),
+        mock_vaapi_wrapper_(new MockVaapiWrapper(VaapiWrapper::kDecode)),
+        mock_vpp_vaapi_wrapper_(new MockVaapiWrapper(VaapiWrapper::kDecode)),
+        weak_ptr_factory_(this) {
+    decoder_thread_.Start();
+
+    // Don't want to go through a vda_->Initialize() because it binds too many
+    // items of the environment. Instead, do all the necessary steps here.
+
+    vda_.decoder_thread_task_runner_ = decoder_thread_.task_runner();
+
+    decoder_delegate_ = std::make_unique<VaapiVideoDecoderDelegate>(
+        &vda_, mock_vaapi_wrapper_, base::DoNothing(), nullptr);
+
+    // Plug in all the mocks and ourselves as the |client_|.
+    vda_.decoder_.reset(mock_decoder_);
+    vda_.decoder_delegate_ = decoder_delegate_.get();
+    vda_.client_ = weak_ptr_factory_.GetWeakPtr();
+    vda_.vaapi_wrapper_ = mock_vaapi_wrapper_;
+    vda_.vpp_vaapi_wrapper_ = mock_vpp_vaapi_wrapper_;
+    vda_.vaapi_picture_factory_.reset(mock_vaapi_picture_factory_);
+
+    // TODO(crbug.com/917999): add IMPORT mode to test variations.
+    vda_.output_mode_ = VideoDecodeAccelerator::Config::OutputMode::ALLOCATE;
+    vda_.profile_ = GetParam().video_codec;
+    vda_.buffer_allocation_mode_ =
+        GetParam().decode_using_client_picture_buffers
+            ? VaapiVideoDecodeAccelerator::BufferAllocationMode::kNone
+            : VaapiVideoDecodeAccelerator::BufferAllocationMode::kSuperReduced;
+
+    vda_.state_ = VaapiVideoDecodeAccelerator::kIdle;
+  }
+
+  VaapiVideoDecodeAcceleratorTest(const VaapiVideoDecodeAcceleratorTest&) =
+      delete;
+  VaapiVideoDecodeAcceleratorTest& operator=(
+      const VaapiVideoDecodeAcceleratorTest&) = delete;
+
+  ~VaapiVideoDecodeAcceleratorTest() {}
+
+  void SetUp() override {
+    in_shm_ = base::UnsafeSharedMemoryRegion::Create(kInputSize);
+  }
+
+  void SetVdaStateToUnitialized() {
+    base::AutoLock auto_lock(vda_.lock_);
+    vda_.state_ = VaapiVideoDecodeAccelerator::kUninitialized;
+  }
+
+  void QueueInputBuffer(BitstreamBuffer bitstream_buffer) {
+    auto id = bitstream_buffer.id();
+    vda_.QueueInputBuffer(bitstream_buffer.ToDecoderBuffer(), id);
+  }
+
+  void AssignPictureBuffers(const std::vector<PictureBuffer>& picture_buffers) {
+    vda_.AssignPictureBuffers(picture_buffers);
+  }
+
+  // Reset epilogue, needed to get |vda_| worker thread out of its Wait().
+  void ResetSequence() {
+    base::RunLoop run_loop;
+    EXPECT_CALL(*mock_decoder_, Reset());
+    EXPECT_CALL(*this, NotifyResetDone())
+        .WillOnce(RunClosure(run_loop.QuitClosure()));
+    vda_.Reset();
+    run_loop.Run();
+  }
+
+  // Try and QueueInputBuffer()s, where we pretend that |mock_decoder_| requests
+  // to kConfigChange: |vda_| will ping us to ProvidePictureBuffers().
+  // If |expect_dismiss_picture_buffers| is signalled, then we expect as well
+  // that |vda_| will emit |num_picture_buffers_to_dismiss| DismissPictureBuffer
+  // calls.
+  void QueueInputBufferSequence(size_t num_pictures,
+                                const gfx::Size& picture_size,
+                                int32_t bitstream_id,
+                                bool expect_dismiss_picture_buffers = false,
+                                size_t num_picture_buffers_to_dismiss = 0) {
+    ::testing::InSequence s;
+    EXPECT_CALL(*mock_decoder_,
+                SetStream(_, IsExpectedDecoderBuffer(kInputSize, nullptr)))
+        .WillOnce(Return());
+    EXPECT_CALL(*mock_decoder_, Decode())
+        .WillOnce(Return(AcceleratedVideoDecoder::kConfigChange));
+
+    EXPECT_CALL(*mock_decoder_, GetBitDepth()).WillOnce(Return(8u));
+    EXPECT_CALL(*mock_decoder_, GetPicSize()).WillOnce(Return(picture_size));
+    EXPECT_CALL(*mock_decoder_, GetVisibleRect())
+        .WillOnce(Return(gfx::Rect(picture_size)));
+    EXPECT_CALL(*mock_decoder_, GetRequiredNumOfPictures())
+        .WillOnce(Return(num_pictures));
+    const size_t kNumReferenceFrames = num_pictures / 2;
+    EXPECT_CALL(*mock_decoder_, GetNumReferenceFrames())
+        .WillOnce(Return(kNumReferenceFrames));
+    EXPECT_CALL(*mock_decoder_, GetProfile())
+        .WillOnce(Return(GetParam().video_codec));
+    EXPECT_CALL(*mock_vaapi_wrapper_, DestroyContext());
+
+    if (expect_dismiss_picture_buffers) {
+      EXPECT_CALL(*this, DismissPictureBuffer(_))
+          .Times(num_picture_buffers_to_dismiss);
+    }
+
+    const size_t expected_num_picture_buffers_requested =
+        vda_.buffer_allocation_mode_ ==
+                VaapiVideoDecodeAccelerator::BufferAllocationMode::kSuperReduced
+            ? num_pictures - kNumReferenceFrames
+            : num_pictures;
+
+    base::RunLoop run_loop;
+
+    EXPECT_CALL(*this,
+                ProvidePictureBuffers(expected_num_picture_buffers_requested, _,
+                                      1, picture_size, _))
+        .WillOnce(RunClosure(run_loop.QuitClosure()));
+
+    BitstreamBuffer bitstream_buffer(bitstream_id, in_shm_.Duplicate(),
+                                     kInputSize);
+
+    QueueInputBuffer(std::move(bitstream_buffer));
+    run_loop.Run();
+  }
+
+  // Calls AssignPictureBuffers(), expecting the corresponding mock calls; we
+  // pretend |mock_decoder_| has kRanOutOfStreamData (i.e. it's finished
+  // decoding) and expect |vda_| to emit a NotifyEndOfBitstreamBuffer().
+  // QueueInputBufferSequence() must have been called beforehand.
+  void AssignPictureBuffersSequence(size_t num_pictures,
+                                    const gfx::Size& picture_size,
+                                    int32_t bitstream_id) {
+    ASSERT_TRUE(vda_.curr_input_buffer_)
+        << "QueueInputBuffer() should have been called";
+
+    // |decode_using_client_picture_buffers| determines the concrete method for
+    // creation of context, surfaces and VaapiPictures.
+    if (GetParam().decode_using_client_picture_buffers) {
+      EXPECT_CALL(*mock_vaapi_wrapper_, CreateContext(picture_size))
+          .WillOnce(Return(true));
+      EXPECT_CALL(*mock_decoder_, GetVisibleRect())
+          .WillRepeatedly(Return(gfx::Rect(picture_size)));
+      EXPECT_CALL(*mock_vaapi_picture_factory_,
+                  MockCreateVaapiPicture(mock_vaapi_wrapper_.get(),
+                                         picture_size, picture_size))
+          .Times(num_pictures);
+    } else {
+      EXPECT_EQ(
+          vda_.buffer_allocation_mode_,
+          VaapiVideoDecodeAccelerator::BufferAllocationMode::kSuperReduced);
+      const size_t kNumReferenceFrames = 1 + num_pictures / 2;
+      EXPECT_CALL(*mock_vaapi_wrapper_,
+                  CreateContextAndSurfaces(
+                      _, picture_size,
+                      std::vector<VaapiWrapper::SurfaceUsageHint>{
+                          VaapiWrapper::SurfaceUsageHint::kVideoDecoder},
+                      kNumReferenceFrames, _))
+          .WillOnce(DoAll(
+              WithArg<4>(Invoke([kNumReferenceFrames](
+                                    std::vector<VASurfaceID>* va_surface_ids) {
+                va_surface_ids->resize(kNumReferenceFrames);
+              })),
+              Return(true)));
+      EXPECT_CALL(*mock_vaapi_wrapper_, DestroySurface(_))
+          .Times(kNumReferenceFrames);
+      EXPECT_CALL(*mock_decoder_, GetVisibleRect())
+          .WillRepeatedly(Return(gfx::Rect(picture_size)));
+      EXPECT_CALL(*mock_vaapi_picture_factory_,
+                  MockCreateVaapiPicture(_, picture_size, picture_size))
+          .Times(num_pictures);
+    }
+
+    ::testing::InSequence s;
+    base::RunLoop run_loop;
+
+    EXPECT_CALL(*mock_decoder_, Decode())
+        .WillOnce(Return(AcceleratedVideoDecoder::kRanOutOfStreamData));
+    EXPECT_CALL(*this, NotifyEndOfBitstreamBuffer(bitstream_id))
+        .WillOnce(RunClosure(run_loop.QuitClosure()));
+
+    const auto tex_target = mock_vaapi_picture_factory_->GetGLTextureTarget();
+    int32_t irrelevant_id = 2;
+    std::vector<PictureBuffer> picture_buffers;
+    for (size_t picture = 0; picture < num_pictures; ++picture) {
+      // The picture buffer id, client id and service texture ids are
+      // arbitrarily chosen.
+      picture_buffers.push_back(
+          {irrelevant_id++, picture_size,
+           PictureBuffer::TextureIds{static_cast<uint32_t>(irrelevant_id++)},
+           PictureBuffer::TextureIds{static_cast<uint32_t>(irrelevant_id++)},
+           tex_target, PIXEL_FORMAT_XRGB});
+    }
+
+    AssignPictureBuffers(picture_buffers);
+    run_loop.Run();
+  }
+
+  // Calls QueueInputBuffer(); we instruct from |mock_decoder_| that it has
+  // kRanOutOfStreamData (i.e. it's finished decoding). This is a fast method
+  // because the Decode() is (almost) immediate.
+  void DecodeOneFrameFast(int32_t bitstream_id) {
+    base::RunLoop run_loop;
+    EXPECT_CALL(*mock_decoder_,
+                SetStream(_, IsExpectedDecoderBuffer(kInputSize, nullptr)))
+        .WillOnce(Return());
+    EXPECT_CALL(*mock_decoder_, Decode())
+        .WillOnce(Return(AcceleratedVideoDecoder::kRanOutOfStreamData));
+    EXPECT_CALL(*this, NotifyEndOfBitstreamBuffer(bitstream_id))
+        .WillOnce(RunClosure(run_loop.QuitClosure()));
+
+    QueueInputBuffer(
+        BitstreamBuffer(bitstream_id, in_shm_.Duplicate(), kInputSize));
+
+    run_loop.Run();
+  }
+
+  // VideoDecodeAccelerator::Client methods.
+  MOCK_METHOD1(NotifyInitializationComplete, void(DecoderStatus));
+  MOCK_METHOD5(
+      ProvidePictureBuffers,
+      void(uint32_t, VideoPixelFormat, uint32_t, const gfx::Size&, uint32_t));
+  MOCK_METHOD1(DismissPictureBuffer, void(int32_t));
+  MOCK_METHOD1(PictureReady, void(const Picture&));
+  MOCK_METHOD1(NotifyEndOfBitstreamBuffer, void(int32_t));
+  MOCK_METHOD0(NotifyFlushDone, void());
+  MOCK_METHOD0(NotifyResetDone, void());
+  MOCK_METHOD1(NotifyError, void(VideoDecodeAccelerator::Error));
+
+  base::test::TaskEnvironment task_environment_;
+
+  std::unique_ptr<VaapiVideoDecoderDelegate> decoder_delegate_;
+
+  // The class under test and a worker thread for it.
+  VaapiVideoDecodeAccelerator vda_;
+  base::Thread decoder_thread_;
+
+  // Ownership passed to |vda_|, but we retain a pointer to it for MOCK checks.
+  raw_ptr<MockAcceleratedVideoDecoder> mock_decoder_;
+  raw_ptr<MockVaapiPictureFactory> mock_vaapi_picture_factory_;
+
+  scoped_refptr<MockVaapiWrapper> mock_vaapi_wrapper_;
+  scoped_refptr<MockVaapiWrapper> mock_vpp_vaapi_wrapper_;
+
+  base::UnsafeSharedMemoryRegion in_shm_;
+
+ private:
+  base::WeakPtrFactory<VaapiVideoDecodeAcceleratorTest> weak_ptr_factory_;
+};
+
+TEST_P(VaapiVideoDecodeAcceleratorTest, SupportedPlatforms) {
+  EXPECT_EQ(VaapiPictureFactory::kVaapiImplementationNone,
+            mock_vaapi_picture_factory_->GetVaapiImplementation(
+                gl::kGLImplementationNone));
+  EXPECT_EQ(VaapiPictureFactory::kVaapiImplementationDrm,
+            mock_vaapi_picture_factory_->GetVaapiImplementation(
+                gl::kGLImplementationEGLGLES2));
+
+#if BUILDFLAG(USE_VAAPI_X11)
+  EXPECT_EQ(VaapiPictureFactory::kVaapiImplementationAngle,
+            mock_vaapi_picture_factory_->GetVaapiImplementation(
+                gl::kGLImplementationEGLANGLE));
+#elif BUILDFLAG(IS_OZONE)
+  EXPECT_EQ(VaapiPictureFactory::kVaapiImplementationDrm,
+            mock_vaapi_picture_factory_->GetVaapiImplementation(
+                gl::kGLImplementationEGLANGLE));
+#endif
+}
+
+// This test checks that QueueInputBuffer() fails when state is kUnitialized.
+TEST_P(VaapiVideoDecodeAcceleratorTest,
+       QueueInputBufferAndErrorWhenVDAUninitialized) {
+  SetVdaStateToUnitialized();
+
+  BitstreamBuffer bitstream_buffer(kBitstreamId, in_shm_.Duplicate(),
+                                   kInputSize);
+
+  EXPECT_CALL(*this,
+              NotifyError(VaapiVideoDecodeAccelerator::PLATFORM_FAILURE));
+  QueueInputBuffer(std::move(bitstream_buffer));
+}
+
+// Verifies that Decode() returning kDecodeError ends up pinging NotifyError().
+TEST_P(VaapiVideoDecodeAcceleratorTest, QueueInputBufferAndDecodeError) {
+  BitstreamBuffer bitstream_buffer(kBitstreamId, in_shm_.Duplicate(),
+                                   kInputSize);
+
+  base::RunLoop run_loop;
+  EXPECT_CALL(*mock_decoder_,
+              SetStream(_, IsExpectedDecoderBuffer(kInputSize, nullptr)))
+      .WillOnce(Return());
+  EXPECT_CALL(*mock_decoder_, Decode())
+      .WillOnce(Return(AcceleratedVideoDecoder::kDecodeError));
+  EXPECT_CALL(*this, NotifyError(VaapiVideoDecodeAccelerator::PLATFORM_FAILURE))
+      .WillOnce(RunClosure(run_loop.QuitClosure()));
+
+  QueueInputBuffer(std::move(bitstream_buffer));
+  run_loop.Run();
+}
+
+TEST_P(VaapiVideoDecodeAcceleratorTest, QueueVP9Profile2AndError) {
+  if (GetParam().video_codec != VP9PROFILE_PROFILE2)
+    GTEST_SKIP() << "The test parameter is not vp9 profile 2";
+
+  BitstreamBuffer bitstream_buffer(kBitstreamId, in_shm_.Duplicate(),
+                                   kInputSize);
+  base::RunLoop run_loop;
+  EXPECT_CALL(*mock_decoder_,
+              SetStream(_, IsExpectedDecoderBuffer(kInputSize, nullptr)))
+      .WillOnce(Return());
+  EXPECT_CALL(*mock_decoder_, Decode())
+      .WillOnce(Return(AcceleratedVideoDecoder::kConfigChange));
+  EXPECT_CALL(*mock_decoder_, GetBitDepth()).WillOnce(Return(10u));
+  EXPECT_CALL(*this, NotifyError(VaapiVideoDecodeAccelerator::PLATFORM_FAILURE))
+      .WillOnce(RunClosure(run_loop.QuitClosure()));
+
+  QueueInputBuffer(std::move(bitstream_buffer));
+  run_loop.Run();
+}
+
+// Verifies a single fast frame decoding..
+TEST_P(VaapiVideoDecodeAcceleratorTest, DecodeOneFrame) {
+  if (GetParam().video_codec == VP9PROFILE_PROFILE2)
+    GTEST_SKIP() << "Decoding profile 2 is not supported";
+  DecodeOneFrameFast(kBitstreamId);
+
+  ResetSequence();
+}
+
+// Tests usual startup sequence: a BitstreamBuffer is enqueued for decode;
+// |vda_| asks for PictureBuffers, that we provide via AssignPictureBuffers().
+TEST_P(VaapiVideoDecodeAcceleratorTest,
+       QueueInputBuffersAndAssignPictureBuffers) {
+  if (GetParam().video_codec == VP9PROFILE_PROFILE2)
+    GTEST_SKIP() << "Decoding profile 2 is not supported";
+  QueueInputBufferSequence(kNumPictures, kPictureSize, kBitstreamId);
+
+  AssignPictureBuffersSequence(kNumPictures, kPictureSize, kBitstreamId);
+
+  ResetSequence();
+}
+
+// Tests a typical resolution change sequence: a BitstreamBuffer is enqueued;
+// |vda_| asks for PictureBuffers, we them provide via AssignPictureBuffers().
+// We then try to enqueue a few BitstreamBuffers of a different resolution: we
+// then expect the old ones to be dismissed and new ones provided.This sequence
+// is purely ingress-wise, i.e. there's no decoded output checks.
+TEST_P(VaapiVideoDecodeAcceleratorTest,
+       QueueInputBuffersAndAssignPictureBuffersAndReallocate) {
+  if (GetParam().video_codec == VP9PROFILE_PROFILE2)
+    GTEST_SKIP() << "Decoding profile 2 is not supported";
+  QueueInputBufferSequence(kNumPictures, kPictureSize, kBitstreamId);
+
+  AssignPictureBuffersSequence(kNumPictures, kPictureSize, kBitstreamId);
+
+  // Decode a few frames. This step is not necessary.
+  for (int i = 0; i < 5; ++i)
+    DecodeOneFrameFast(kBitstreamId + i);
+
+  QueueInputBufferSequence(kNewNumPictures, kNewPictureSize, kBitstreamId,
+                           true /* expect_dismiss_picture_buffers */,
+                           kNumPictures /* num_picture_buffers_to_dismiss */);
+
+  AssignPictureBuffersSequence(kNewNumPictures, kNewPictureSize, kBitstreamId);
+
+  ResetSequence();
+}
+
+constexpr TestParams kTestCases[] = {
+    {H264PROFILE_MIN, false /* decode_using_client_picture_buffers */},
+    {H264PROFILE_MIN, true /* decode_using_client_picture_buffers */},
+    {VP8PROFILE_MIN, false /* decode_using_client_picture_buffers */},
+    {VP9PROFILE_MIN, false /* decode_using_client_picture_buffers */},
+    {VP9PROFILE_MIN, true /* decode_using_client_picture_buffers */},
+    {VP9PROFILE_PROFILE2, false /* decode_using_client_picture_buffers */},
+};
+
+INSTANTIATE_TEST_SUITE_P(All,
+                         VaapiVideoDecodeAcceleratorTest,
+                         ValuesIn(kTestCases));
+
+}  // namespace media
diff --git a/ui/gl/BUILD.gn b/ui/gl/BUILD.gn
index e1df9ac..0143610 100644
--- a/ui/gl/BUILD.gn
+++ b/ui/gl/BUILD.gn
@@ -10,6 +10,7 @@ import("//build/config/linux/pkg_config.gni")
 import("//build/config/ozone.gni")
 import("//build/config/ui.gni")
 import("//gpu/vulkan/features.gni")
+import("//media/gpu/args.gni")
 import("//testing/test.gni")
 import("//third_party/angle/gni/angle.gni")
 import("//third_party/dawn/scripts/dawn_features.gni")
@@ -572,6 +573,10 @@ test("gl_unittests") {
     ]
   }
 
+  if (use_vaapi) {
+    sources += [ "gl_image_gl_texture_unittest.cc" ]
+  }
+
   include_dirs = [ "//third_party/khronos" ]
 
   deps = [
@@ -591,6 +596,19 @@ test("gl_unittests") {
     "//ui/platform_window:platform_impls",
   ]
 
+  if (use_vaapi) {
+    # gl_image_gl_texture_unittest.cc cannot easily be made to run as part of
+    # media_unittests due to its reliance on particular GL environment setup
+    # necessary for gl_image_test_template.h. Instead just leave it here until
+    # it is eliminated, at which point these deps can also be eliminated.
+    # TODO(crbug.com/1310018): Eliminate these deps once
+    # gl_image_gl_texture_unittest.cc is eliminated.
+    deps += [
+      "//media/gpu",
+      "//media/gpu/vaapi",
+    ]
+  }
+
   data_deps = [
     "//testing/buildbot/filters:gl_unittests_filters",
     "//third_party/mesa_headers",
diff --git a/ui/gl/gl_image_gl_texture_unittest.cc b/ui/gl/gl_image_gl_texture_unittest.cc
new file mode 100644
index 0000000..4ba8075
--- /dev/null
+++ b/ui/gl/gl_image_gl_texture_unittest.cc
@@ -0,0 +1,132 @@
+// Copyright 2017 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "media/gpu/vaapi/gl_image_gl_texture.h"
+
+#include "build/build_config.h"
+#include "ui/gl/gl_bindings.h"
+#include "ui/gl/test/gl_image_test_template.h"
+
+// TODO(crbug.com/969798): Fix memory leaks in tests and re-enable on LSAN.
+#ifdef LEAK_SANITIZER
+#define MAYBE_GLTexture2DToDmabuf DISABLED_GLTexture2DToDmabuf
+#else
+#define MAYBE_GLTexture2DToDmabuf GLTexture2DToDmabuf
+#endif
+
+// TYPED_TEST_P() and REGISTER_TYPED_TEST_SUITE_P() don't do macro expansion on
+// their parameters, making the MAYBE_ technique above not work -- these macros
+// are a workaround.
+#define TYPED_TEST_P_WITH_EXPANSION(SuiteName, TestName) \
+  TYPED_TEST_P(SuiteName, TestName)
+#define REGISTER_TYPED_TEST_SUITE_P_WITH_EXPANSION(SuiteName, ...) \
+  REGISTER_TYPED_TEST_SUITE_P(SuiteName, __VA_ARGS__)
+
+namespace gl {
+
+namespace {
+
+const uint8_t kImageColor[] = {0x30, 0x40, 0x10, 0xFF};
+
+template <gfx::BufferFormat format>
+class GLImageGLTextureTestDelegate : public GLImageTestDelegateBase {
+ public:
+  bool SkipTest(GLDisplay* display) const override {
+    GLDisplayEGL* display_egl = static_cast<GLDisplayEGL*>(display);
+    if (!display_egl->ext->b_EGL_MESA_image_dma_buf_export) {
+      LOG(WARNING) << "Skip test, missing extension "
+                   << "EGL_MESA_image_dma_buf_export";
+      return true;
+    }
+
+    return false;
+  }
+
+  scoped_refptr<media::GLImageGLTexture> CreateSolidColorImage(
+      const gfx::Size& size,
+      const uint8_t color[4]) const {
+    GLuint texture_id = GLTestHelper::CreateTexture(GetTextureTarget());
+    EXPECT_NE(0u, texture_id);
+
+    std::unique_ptr<uint8_t[]> pixels(
+        new uint8_t[BufferSizeForBufferFormat(size, format)]);
+    GLTestSupport::SetBufferDataToColor(
+        size.width(), size.height(),
+        static_cast<int>(RowSizeForBufferFormat(size.width(), format, 0)), 0,
+        format, color, pixels.get());
+
+    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, size.width(), size.height(), 0,
+                 GL_RGBA, GL_UNSIGNED_BYTE, pixels.get());
+
+    auto image = media::GLImageGLTexture::CreateFromTextureForTesting(
+        size, format, texture_id);
+    EXPECT_TRUE(image);
+
+    glDeleteTextures(1, &texture_id);
+    return image;
+  }
+
+  unsigned GetTextureTarget() const { return GL_TEXTURE_2D; }
+
+  const uint8_t* GetImageColor() const { return kImageColor; }
+
+  int GetAdmissibleError() const { return 0; }
+
+  gfx::BufferFormat GetBufferFormat() const { return format; }
+};
+
+template <typename GLImageTestDelegate>
+class GLImageGLTextureToDmabufTest : public GLImageTest<GLImageTestDelegate> {};
+
+TYPED_TEST_SUITE_P(GLImageGLTextureToDmabufTest);
+
+TYPED_TEST_P_WITH_EXPANSION(GLImageGLTextureToDmabufTest,
+                            MAYBE_GLTexture2DToDmabuf) {
+  if (this->delegate_.SkipTest(this->display_)) {
+    return;
+  }
+
+  const gfx::Size image_size(64, 64);
+  const uint8_t* image_color = this->delegate_.GetImageColor();
+
+  scoped_refptr<media::GLImageGLTexture> image =
+      this->delegate_.CreateSolidColorImage(image_size, image_color);
+  ASSERT_TRUE(image);
+
+  gfx::NativePixmapHandle native_pixmap_handle =
+      image->ExportHandleForTesting();
+
+  for (auto& plane : native_pixmap_handle.planes) {
+    EXPECT_TRUE(plane.fd.is_valid());
+  }
+}
+
+// This test verifies that GLImageGLTexture can be exported as dmabuf fds.
+REGISTER_TYPED_TEST_SUITE_P_WITH_EXPANSION(GLImageGLTextureToDmabufTest,
+                                           MAYBE_GLTexture2DToDmabuf);
+
+using GLImageTestTypes = testing::Types<
+    GLImageGLTextureTestDelegate<gfx::BufferFormat::RGBX_8888>,
+    GLImageGLTextureTestDelegate<gfx::BufferFormat::RGBA_8888>,
+    GLImageGLTextureTestDelegate<gfx::BufferFormat::BGRX_8888>,
+    GLImageGLTextureTestDelegate<gfx::BufferFormat::BGRA_8888>,
+    GLImageGLTextureTestDelegate<gfx::BufferFormat::RGBA_1010102>,
+    GLImageGLTextureTestDelegate<gfx::BufferFormat::BGRA_1010102>>;
+
+#if !defined(MEMORY_SANITIZER)
+// Fails under MSAN: crbug.com/886995
+INSTANTIATE_TYPED_TEST_SUITE_P(GLImageGLTexture, GLImageTest, GLImageTestTypes);
+
+INSTANTIATE_TYPED_TEST_SUITE_P(GLImageGLTexture,
+                               GLImageOddSizeTest,
+                               GLImageTestTypes);
+
+INSTANTIATE_TYPED_TEST_SUITE_P(GLImageGLTexture,
+                               GLImageGLTextureToDmabufTest,
+                               GLImageTestTypes);
+#endif
+
+}  // namespace
+
+}  // namespace gl
