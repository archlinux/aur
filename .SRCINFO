pkgbase = python-open-clip-torch
	pkgdesc = Open source implementation of OpenAI's CLIP (Contrastive Language-Image Pre-training).
	pkgver = 2.9.3
	pkgrel = 1
	url = https://github.com/mlfoundations/open_clip
	arch = any
	license = Apache
	makedepends = python-setuptools
	depends = python-protobuf
	depends = python-huggingface-hub
	depends = python-sentencepiece-git
	depends = python-pandas
	depends = python-regex
	depends = python-torchvision
	depends = python-tqdm
	depends = python-webdataset
	depends = python-ftfy
	source = https://github.com/mlfoundations/open_clip/archive/refs/tags/v2.9.3.zip
	sha256sums = f4226f7e2e0e76a0e9ef8c1b24ffbd4d6b0919047c4725340a8b40c195ab1b2c

pkgname = python-open-clip-torch
