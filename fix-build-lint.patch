commit cc02d0addb97bb30237019965ba06c6aae67ac76
Author: gesh <gesh@gesh.uni.cx>
Date:   Sun Nov 12 18:24:29 2023 +0200

    Fix build, lint
    
    * Restore static versions (at least until repo starts tagging versions)
      * Add (commented-out) [tool.setuptools_scm] section to silence
        warnings once repo uses dynamic versioning
    * Restore unnecessary edits to pyproject.toml
      * Restore version bounds (guessed for bs4)
      * Restore classifiers, keywords, authors
      * Relax python version bounds
      * Explicitly use standard GPL3 text
    * Pylint-clean for python >=3.6
      * In contrast to upstream guidance, Python 3.6 already includes
        f-strings, hence no need to remove them
      * Convert `| None` to uses of `Optional[]` to silence warnings on
        Pythons older than 3.10
      * Use more specific exceptions
      * Clean up early-exit logic, drop useless exception catches
      * Standardize names
    * Misc improvements
      * Fix `download_bibtex()` type
      * Add sci-hub mirrors

diff --git a/papis-scihub/papis_scihub/plugin.py b/papis-scihub/papis_scihub/plugin.py
index 38ac36e..de67a55 100644
--- a/papis-scihub/papis_scihub/plugin.py
+++ b/papis-scihub/papis_scihub/plugin.py
@@ -1,36 +1,32 @@
 from urllib.parse import urlparse
+from typing import Optional
+from requests.exceptions import RequestException
 
 import doi
 import papis.downloaders
 from bs4 import BeautifulSoup
 
-
-BASE_URLS = ("http://sci-hub.ee",)
-
+BASE_URLS = (f"http://sci-hub.{tld}" for tld in ["ee","se","st","ru"])
 
 class Downloader(papis.downloaders.Downloader):
     def __init__(self, uri: str) -> None:
         papis.downloaders.Downloader.__init__(self, uri=uri, name="sci-hub")
         self.expected_document_extension = "pdf"
         self.priority = 1
-
-        try:
-            self._get_active_server_url()
-        except Exception as e:
-            raise e
-
+        self._get_active_server_url()
         self.doi = _extract_doi(uri)
         self._body = self.session.get(
             f"{self.base_url}/{self.doi}",
             verify=False
         )
+        self.bibtex_data = ""
 
     @classmethod
-    def match(cls, url: str) -> papis.downloaders.Downloader | None:
+    def match(cls, url: str) -> Optional[papis.downloaders.Downloader]:
         try:
             _extract_doi(url)
             return Downloader(url)
-        except Exception:
+        except (RequestException, ValueError):
             return None
 
     def _get_active_server_url(self) -> None:
@@ -38,35 +34,36 @@ class Downloader(papis.downloaders.Downloader):
             if self._ping_server(base_url):
                 self.base_url = base_url
                 return
-        raise Exception("No Sci-Hub servers can be pinged")
+        raise RequestException("No Sci-Hub servers can be pinged")
 
     def _ping_server(self, base_url: str) -> bool:
         try:
             ping = self.session.get(base_url, timeout=1, verify=False)
-            if ping.status_code != 200:
-                self.logger.error(f"server {base_url} is down")
-                return False
-            else:
-                self.logger.debug(f"server {base_url} is up")
-                return True
-        except Exception:
+        except RequestException:
             return False
 
-    def get_doi(self) -> str | None:
+        if ping.status_code != 200:
+            self.logger.error(f"server {base_url} is down")
+            return False
+
+        self.logger.debug(f"server {base_url} is up")
+        return True
+
+    def get_doi(self) -> Optional[str]:
         return self.doi
 
-    def get_document_url(self) -> str | None:
-        s = BeautifulSoup(self._body.content, "html.parser")
-        iframe = s.find("iframe")
-        if iframe:
-            src = iframe.get("src")
-            if src.startswith("//"):
-                src = f"https:{src}"
-            return src
-        else:
+    def get_document_url(self) -> Optional[str]:
+        soup = BeautifulSoup(self._body.content, "html.parser")
+        iframe = soup.find("iframe")
+        if not iframe:
             return None
 
-    def download_bibtex(self) -> str:
+        src = iframe.get("src")
+        if src.startswith("//"):
+            src = f"https:{src}"
+        return src
+
+    def download_bibtex(self) -> None:
         self.bibtex_data = self.session.get(
             f"https://doi.org/{self.doi}",
             headers={"accept": "application/x-bibtex"}
@@ -83,6 +80,6 @@ def _extract_doi(url: str) -> str:
     try:
         doi.validate_doi(doi_)
         return doi_
-    except Exception as e:
-        raise e(f"Cannot extract a valid DOI from the provided URL: {url}")
-
+    except ValueError as err:
+        raise ValueError(
+            f"Cannot extract a valid DOI from the provided URL: {url}") from err
diff --git a/papis-scihub/pyproject.toml b/papis-scihub/pyproject.toml
index e2a04ad..313424d 100644
--- a/papis-scihub/pyproject.toml
+++ b/papis-scihub/pyproject.toml
@@ -1,37 +1,60 @@
 [build-system]
-requires = ["setuptools", "setuptools-scm"]
-build-backend = "setuptools.build_meta"
+requires = ["setuptools"]
+#requires = ["setuptools", "setuptools-scm"]
+#build-backend = "setuptools.build_meta"
+
+#[tool.setuptools_scm]
 
 [project]
 name = "papis-scihub"
 description = "Sci-Hub plugin for the Papis bibliography manager"
 readme = "README.md"
-requires-python = ">=3.10"
-license = {file = "LICENSE"}
+requires-python = ">=3.6"
+license = {text = "GPL-3.0-only"}
 authors = [
-    {name = "Raj Magesh Gauthaman", email = "rgautha1@jh.edu"}
+    {name = "Gesh", email = "gesh@gesh.uni.cx"},
+    {name = "Raj Magesh Gauthaman", email = "rgautha1@jh.edu"},
+    {name = "Alejandro Gallo", email = "aamsgallo@gmail.com"}
 ]
 keywords = [
     "papis",
     "sci-hub",
+    "scihub",
     "bibliography",
+    "bibtex",
+    "management",
+    "cli",
 ]
 classifiers = [
+    "Environment :: Console",
+    "Environment :: Console :: Curses",
+    "Intended Audience :: Developers",
+    "Intended Audience :: System Administrators",
     "Development Status :: 4 - Beta",
     "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
     "Natural Language :: English",
+    "Operating System :: MacOS",
     "Operating System :: POSIX :: Linux",
-    "Programming Language :: Python :: 3",
-    "Topic :: Software Development :: Libraries :: Python Modules",
+    "Operating System :: POSIX",
+    "Operating System :: Unix",
+    "Programming Language :: Python :: 3.6",
+    "Programming Language :: Python :: 3.7",
+    "Programming Language :: Python :: 3.8",
+    "Programming Language :: Python :: 3.9",
+    "Programming Language :: Python :: 3.10",
+    "Programming Language :: Python :: 3.11",
+    "Topic :: Utilities",
     "Typing :: Typed",
 ]
 urls = {repository = "https://github.com/papis/scripts"}
 dependencies = [
-    "papis",
-    "beautifulsoup4",
-    "python-doi",
+    "papis>=0.9",
+    "beautifulsoup4>=4.11.0",
+    "python-doi>=0.1.0",
 ]
-dynamic = ["version"]
+
+version = "1.4.0"
+#dynamic = ["version"]
 
 [project.entry-points."papis.importer"]
 scihub = "papis_scihub.plugin:Downloader"
